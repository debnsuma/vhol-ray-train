{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Distributed Training with DeepSpeed and Ray Train\n\nThis notebook demonstrates using Microsoft's DeepSpeed with Ray Train for memory-efficient distributed training.\n\n**Learning Objectives:**\n1. Configure DeepSpeed ZeRO for memory optimization\n2. Use DeepSpeed's configuration-based approach\n3. Compare with FSDP2\n\n## What is DeepSpeed?\n\n[DeepSpeed](https://www.deepspeed.ai/) is Microsoft's deep learning optimization library:\n\n- **ZeRO**: Partitions optimizer states, gradients, and parameters across GPUs\n- **Mixed Precision**: FP16/BF16 with automatic loss scaling\n- **CPU Offloading**: Extends training beyond GPU memory\n\n**When to use DeepSpeed:**\n- Training large models (billions of parameters)\n- Using HuggingFace Transformers\n- Prefer configuration-driven setup"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## DeepSpeed ZeRO Stages\n",
    "\n",
    "ZeRO progressively partitions training state:\n",
    "\n",
    "| Stage | Partitions | Memory Reduction |\n",
    "|-------|------------|------------------|\n",
    "| ZeRO-1 | Optimizer states | ~25% |\n",
    "| ZeRO-2 | + Gradients | ~50% |\n",
    "| ZeRO-3 | + Parameters | ~75% |\n",
    "| ZeRO-Infinity | + CPU/NVMe offload | ~90% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Key Differences from FSDP2\n",
    "\n",
    "| Aspect | FSDP2 | DeepSpeed |\n",
    "|--------|-------|-----------|\n",
    "| Setup | `fully_shard(model, ...)` | `deepspeed.initialize(model, config)` |\n",
    "| Optimizer | User creates separately | Managed by DeepSpeed |\n",
    "| Backward | `loss.backward()` | `model.backward(loss)` |\n",
    "| Config | Python API | JSON/dict config |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "## Step 1: Environment Setup\n\nCheck Ray cluster status and configure environment.\n\n**Requirements:**\n- Ray cluster with at least 2 GPU workers\n- DeepSpeed installed on all workers\n- CUDA runtime (nvcc not required)"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2026-02-02 06:54:34.492097 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Active:\n",
      " 1 head\n",
      " 1 1xL4:16CPU-64GB-2\n",
      "Idle:\n",
      " 1 1xL4:16CPU-64GB-1\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Total Usage:\n",
      " 0.0/32.0 CPU\n",
      " 0.0/2.0 GPU\n",
      " 0.0/2.0 anyscale/accelerator_shape:1xL4\n",
      " 0.0/1.0 anyscale/cpu_only:true\n",
      " 0.0/1.0 anyscale/node-group:1xL4:16CPU-64GB-1\n",
      " 0.0/1.0 anyscale/node-group:1xL4:16CPU-64GB-2\n",
      " 0.0/1.0 anyscale/node-group:head\n",
      " 0.0/3.0 anyscale/provider:aws\n",
      " 0.0/3.0 anyscale/region:us-west-2\n",
      " 0B/160.00GiB memory\n",
      " 16.30KiB/44.64GiB object_store_memory\n",
      "\n",
      "From request_resources:\n",
      " (none)\n",
      "Pending Demands:\n",
      " (no resource demands)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Check Ray cluster status\n",
    "!ray status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "%%bash\npip install -q torch torchvision deepspeed"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-02 06:54:38,093] [WARNING] [real_accelerator.py:209:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "PyTorch version: 2.10.0+cu128\n",
      "Ray version: 2.53.0\n",
      "DeepSpeed version: 0.18.5\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "import ray\n",
    "import deepspeed\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Ray version: {ray.__version__}\")\n",
    "print(f\"DeepSpeed version: {deepspeed.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# Setup - configure environment for DeepSpeed\nimport os\n\n# Ray Train V2 API\nos.environ[\"RAY_TRAIN_V2_ENABLED\"] = \"1\"\n\n# DeepSpeed environment settings (avoid nvcc checks on clusters without CUDA toolkit)\nos.environ[\"DS_BUILD_OPS\"] = \"0\"\nos.environ[\"DS_SKIP_CUDA_CHECK\"] = \"1\"\n\nimport tempfile\nimport uuid\nimport torch"
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 2: Model Definition\n",
    "\n",
    "Same Vision Transformer as FSDP2 tutorial - DeepSpeed wraps your existing PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "from torchvision.models import VisionTransformer\nfrom torchvision.datasets import FashionMNIST\nfrom torchvision.transforms import ToTensor, Normalize, Compose\n\ndef init_model():\n    \"\"\"Initialize Vision Transformer for FashionMNIST.\"\"\"\n    model = VisionTransformer(\n        image_size=28, patch_size=7, num_layers=10, num_heads=2,\n        hidden_dim=128, mlp_dim=128, num_classes=10,\n    )\n    model.conv_proj = torch.nn.Conv2d(1, 128, kernel_size=7, stride=7)\n    return model\n\n# Verify model\ntest_model = init_model()\nprint(f\"Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\ndel test_model"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 3: DeepSpeed Configuration\n",
    "\n",
    "DeepSpeed uses a configuration dictionary instead of Python API. Key sections:\n",
    "- **optimizer**: DeepSpeed manages the optimizer internally\n",
    "- **fp16**: Mixed precision settings\n",
    "- **zero_optimization**: ZeRO stage and settings\n",
    "- **train_micro_batch_size_per_gpu**: Batch size configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "def get_deepspeed_config(batch_size=64, lr=0.001):\n    \"\"\"DeepSpeed ZeRO Stage 2 configuration.\"\"\"\n    return {\n        \"optimizer\": {\n            \"type\": \"Adam\",\n            \"params\": {\"lr\": lr, \"betas\": [0.9, 0.999], \"eps\": 1e-8}\n        },\n        \"fp16\": {\"enabled\": False},  # Disabled for simplicity\n        \"zero_optimization\": {\n            \"stage\": 2,\n            \"allgather_bucket_size\": 2e8,\n            \"reduce_bucket_size\": 2e8,\n            \"overlap_comm\": True,\n            \"contiguous_gradients\": True,\n        },\n        \"train_micro_batch_size_per_gpu\": batch_size,\n        \"gradient_accumulation_steps\": 1,\n        \"gradient_clipping\": 1.0,\n        \"steps_per_print\": 1000,\n    }\n\n# Preview config\nimport json\nprint(json.dumps(get_deepspeed_config(), indent=2))"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 4: DeepSpeed Checkpointing\n",
    "\n",
    "DeepSpeed has built-in checkpointing methods - simpler than FSDP2's DCP approach:\n",
    "- `model.save_checkpoint(dir)` - Save checkpoint\n",
    "- `model.load_checkpoint(dir)` - Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "import ray.train\nimport torch.distributed as dist\n\ndef save_checkpoint(model_engine, metrics, epoch):\n    \"\"\"Save DeepSpeed checkpoint and report to Ray Train.\"\"\"\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        model_engine.save_checkpoint(tmp_dir, tag=f\"epoch_{epoch}\", client_state={\"epoch\": epoch})\n        dist.barrier()\n        ray.train.report(metrics, checkpoint=ray.train.Checkpoint.from_directory(tmp_dir))\n\ndef load_checkpoint(model_engine, ckpt):\n    \"\"\"Load DeepSpeed checkpoint.\"\"\"\n    with ckpt.as_directory() as ckpt_dir:\n        tags = [d for d in os.listdir(ckpt_dir) if d.startswith(\"epoch_\")]\n        if tags:\n            _, client_state = model_engine.load_checkpoint(ckpt_dir, tag=sorted(tags)[-1])\n            return client_state.get(\"epoch\", 0) if client_state else 0\n    return 0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "def save_model_for_inference(model_engine, world_rank):\n    \"\"\"Save consolidated model for inference (rank 0 only).\"\"\"\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        ckpt = None\n        if world_rank == 0:\n            torch.save(model_engine.module.state_dict(), os.path.join(tmp_dir, \"full-model.pt\"))\n            ckpt = ray.train.Checkpoint.from_directory(tmp_dir)\n        dist.barrier()\n        ray.train.report({}, checkpoint=ckpt, checkpoint_dir_name=\"full_model\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "## Step 5: Training Function\n\nKey differences from FSDP2:\n- `deepspeed.initialize()` creates model engine and optimizer\n- `model.backward(loss)` replaces `loss.backward()`\n- `model.step()` replaces `optimizer.step()`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "import ray.train.torch\nfrom torch.nn import CrossEntropyLoss\nfrom torch.utils.data import DataLoader\n\ndef train_func(config):\n    \"\"\"DeepSpeed training function.\"\"\"\n    import os\n    \n    # Set DeepSpeed environment on worker before import\n    os.environ[\"DS_BUILD_OPS\"] = \"0\"\n    os.environ[\"DS_SKIP_CUDA_CHECK\"] = \"1\"\n    \n    import deepspeed\n    \n    # Model setup with DeepSpeed\n    model = init_model()\n    ds_config = get_deepspeed_config(batch_size=config.get('batch_size', 64), lr=config.get('lr', 0.001))\n    model_engine, optimizer, _, _ = deepspeed.initialize(model=model, config=ds_config, model_parameters=model.parameters())\n    device = model_engine.device\n    \n    criterion = CrossEntropyLoss()\n    \n    # Resume from checkpoint if available\n    start_epoch = 0\n    if ray.train.get_checkpoint():\n        start_epoch = load_checkpoint(model_engine, ray.train.get_checkpoint()) + 1\n    \n    # Data loading with DistributedSampler\n    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n    train_data = FashionMNIST(root=tempfile.gettempdir(), train=True, download=True, transform=transform)\n    sampler = torch.utils.data.DistributedSampler(\n        train_data,\n        num_replicas=ray.train.get_context().get_world_size(),\n        rank=ray.train.get_context().get_world_rank(),\n        shuffle=True,\n    )\n    train_loader = DataLoader(train_data, batch_size=config.get('batch_size', 64), sampler=sampler)\n    \n    world_rank = ray.train.get_context().get_world_rank()\n    \n    # Training loop\n    for epoch in range(start_epoch, config.get('epochs', 1)):\n        sampler.set_epoch(epoch)\n        total_loss, num_batches = 0.0, 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            # DeepSpeed forward/backward\n            outputs = model_engine(images)\n            loss = criterion(outputs, labels)\n            model_engine.backward(loss)\n            model_engine.step()\n            \n            total_loss += loss.item()\n            num_batches += 1\n        \n        avg_loss = total_loss / num_batches\n        save_checkpoint(model_engine, {\"loss\": avg_loss, \"epoch\": epoch}, epoch)\n        if world_rank == 0:\n            print(f\"Epoch {epoch}: loss={avg_loss:.4f}\")\n    \n    # Save final model\n    save_model_for_inference(model_engine, world_rank)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Step 6: Launch Distributed Training\n",
    "\n",
    "Ray Train setup is nearly identical to FSDP2 - DeepSpeed handles everything through its config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "import ray.train.torch\n\n# Configuration\nexperiment_name = f\"deepspeed_{uuid.uuid4().hex[:8]}\"\nscaling_config = ray.train.ScalingConfig(num_workers=2, use_gpu=True)\n\n# Set environment variables on workers to avoid DeepSpeed nvcc checks\nrun_config = ray.train.RunConfig(\n    storage_path=\"/mnt/cluster_storage/\",\n    name=experiment_name,\n)\ntrain_config = {\"epochs\": 1, \"lr\": 0.001, \"batch_size\": 64}\n\nprint(f\"Experiment: {experiment_name}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "# Run training\ntrainer = ray.train.torch.TorchTrainer(\n    train_loop_per_worker=train_func,\n    scaling_config=scaling_config,\n    train_loop_config=train_config,\n    run_config=run_config,\n)\nresult = trainer.fit()\nprint(f\"Training complete! Checkpoint: {result.checkpoint}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": "## Step 7: Inspect Training Artifacts\n\nDeepSpeed checkpoint structure:\n- `epoch_N/` - Checkpoint with model and optimizer states\n- `full_model/` - Consolidated model for inference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# List artifacts\nstorage_path = f\"/mnt/cluster_storage/{experiment_name}/\"\nprint(f\"Artifacts in {storage_path}:\")\nfor item in sorted(os.listdir(storage_path)):\n    print(f\"  {item}/\" if os.path.isdir(os.path.join(storage_path, item)) else f\"  {item}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 8: Load Model for Inference\n",
    "\n",
    "Loading is identical to FSDP2 - we saved a standard PyTorch checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "# Load model for inference\nmodel_path = f\"/mnt/cluster_storage/{experiment_name}/full_model/full-model.pt\"\nprint(f\"Loading from: {model_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "inference_model = init_model()\ninference_model.load_state_dict(torch.load(model_path, map_location='cpu', weights_only=True))\ninference_model.eval()\nprint(\"Model loaded.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "# Test inference\ntest_data = FashionMNIST(root=\"/tmp\", train=False, download=True, transform=Compose([ToTensor(), Normalize((0.5,), (0.5,))]))\nwith torch.no_grad():\n    sample = test_data.data[0].reshape(1, 1, 28, 28).float()\n    output = inference_model(sample)\nprint(f\"Inference output shape: {output.shape}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": "## Optional: TensorBoard Profiling\n\nAdd PyTorch profiler to the training loop:\n\n```python\nfrom torch.profiler import profile, ProfilerActivity, tensorboard_trace_handler\n\nwith profile(\n    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n    on_trace_ready=tensorboard_trace_handler(\"./tensorboard\"),\n) as prof:\n    # training loop\n    prof.step()\n```\n\nView with: `tensorboard --logdir=./tensorboard`"
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": "## Step 9: Cleanup\n\nClean up GPU and CPU memory."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": "import gc\n\n# Cleanup\ngc.collect()\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\nprint(\"Cleanup complete.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": "## Summary\n\nThis tutorial covered:\n1. **DeepSpeed ZeRO** - Memory optimization via state partitioning\n2. **Ray Train integration** - Multi-GPU distributed training\n3. **Built-in checkpointing** - Simpler than FSDP2's DCP\n\n**Key differences from FSDP2:**\n- Configuration-based (dict) vs Python API\n- DeepSpeed manages optimizer internally\n- `model.backward(loss)` and `model.step()` API\n\n**Next Steps:**\n- Try ZeRO Stage 3 for larger models\n- Enable CPU offloading for memory-constrained scenarios\n\n**Resources:**\n- [DeepSpeed Documentation](https://www.deepspeed.ai/)\n- [Ray Train DeepSpeed Guide](https://docs.ray.io/en/latest/train/deepspeed.html)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}