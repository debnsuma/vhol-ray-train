{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Distributed Training with DeepSpeed and Ray Train\n",
    "\n",
    "This notebook will show you how to use Microsoft's DeepSpeed library with Ray Train for efficient distributed training. If you've completed the [FSDP2 tutorial](./FSDP2_RayTrain_Tutorial.ipynb), this notebook shows how to achieve similar memory optimization using DeepSpeed's ZeRO (Zero Redundancy Optimizer) technology.\n",
    "\n",
    "In this tutorial, you:\n",
    "1. Learn how DeepSpeed ZeRO partitions optimizer states, gradients, and parameters across GPUs\n",
    "2. Configure DeepSpeed using JSON-like configuration dictionaries\n",
    "3. Use DeepSpeed's built-in checkpointing methods\n",
    "4. Compare DeepSpeed with FSDP2 to understand when to use each approach\n",
    "5. Train a Vision Transformer model using DeepSpeed ZeRO Stage 2\n",
    "\n",
    "## What is DeepSpeed?\n",
    "\n",
    "[DeepSpeed](https://www.deepspeed.ai/) is a deep learning optimization library developed by Microsoft that makes distributed training **easy, efficient, and effective**. It's particularly known for:\n",
    "\n",
    "> DeepSpeed ZeRO (Zero Redundancy Optimizer) partitions optimizer states, gradients, and parameters across data-parallel workers. This enables training models that are much larger than what fits on a single GPU, with minimal code changes.\n",
    "\n",
    "Key features:\n",
    "- **ZeRO (Zero Redundancy Optimizer)**: Memory optimization that partitions optimizer states, gradients, and parameters across GPUs\n",
    "- **Mixed Precision Training**: FP16/BF16 training with automatic loss scaling\n",
    "- **CPU/NVMe Offloading**: Extend training beyond GPU memory limits (ZeRO-Infinity)\n",
    "- **Gradient Checkpointing**: Trade compute for memory\n",
    "- **Sparse Attention**: Efficient attention for long sequences\n",
    "\n",
    "## FSDP2 vs DeepSpeed: When to Use Which?\n",
    "\n",
    "| Aspect | PyTorch FSDP2 | DeepSpeed ZeRO |\n",
    "|--------|---------------|----------------|\n",
    "| **Origin** | PyTorch native | Microsoft Research |\n",
    "| **Ecosystem** | Tight PyTorch integration | Framework-agnostic (works with HuggingFace, Lightning, etc.) |\n",
    "| **Configuration** | Python API | JSON config files |\n",
    "| **CPU Offloading** | Basic support | Advanced (ZeRO-Infinity with NVMe) |\n",
    "| **Optimizer Fusion** | Limited | Built-in fused optimizers |\n",
    "| **Adoption** | Growing | Widely used in LLM training |\n",
    "| **Best For** | PyTorch-native workflows | Large language models, HuggingFace |\n",
    "\n",
    "**Key Insight**: DeepSpeed is the de-facto standard for training large language models (GPT, LLaMA, etc.). Understanding both FSDP2 and DeepSpeed gives you flexibility to choose the right tool for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## DeepSpeed ZeRO Stages Explained\n",
    "\n",
    "ZeRO progressively partitions training state across GPUs:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     Memory Consumption Per GPU                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  No ZeRO     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%            â”‚\n",
    "â”‚  (DDP)       Parameters + Gradients + Optimizer States                  â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  ZeRO-1      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 75%                        â”‚\n",
    "â”‚  (Stage 1)   Parameters + Gradients + Optimizer States (partitioned)   â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  ZeRO-2      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 50%                                   â”‚\n",
    "â”‚  (Stage 2)   Parameters + Gradients (partitioned) + Opt States (part.) â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  ZeRO-3      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 25%                                            â”‚\n",
    "â”‚  (Stage 3)   Parameters (partitioned) + Grads (part.) + Opt (part.)    â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  ZeRO-Inf    [â–ˆâ–ˆâ–ˆ] ~10% (with CPU/NVMe offload)                         â”‚\n",
    "â”‚  (Infinity)  Everything offloaded when not in use                       â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Stage Comparison with FSDP2\n",
    "\n",
    "| ZeRO Stage | FSDP2 Equivalent | What's Partitioned |\n",
    "|------------|------------------|--------------------|\n",
    "| Stage 1 | N/A (DDP-like) | Optimizer states only |\n",
    "| Stage 2 | `reshard_after_forward=False` | Optimizer states + Gradients |\n",
    "| Stage 3 | `reshard_after_forward=True` | Everything (params + grads + optimizer) |\n",
    "| ZeRO-Infinity | `CPUOffloadPolicy()` | Stage 3 + CPU/NVMe offloading |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Key Differences: FSDP2 vs DeepSpeed in Code\n",
    "\n",
    "Here's a side-by-side comparison of the key changes:\n",
    "\n",
    "### Model Wrapping\n",
    "\n",
    "```python\n",
    "# FSDP2 Approach\n",
    "from torch.distributed.fsdp import fully_shard\n",
    "model.to(device)\n",
    "fully_shard(model, mesh=mesh, ...)  # Wrap model with FSDP2\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "# DeepSpeed Approach  \n",
    "import deepspeed\n",
    "model, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model,\n",
    "    config=deepspeed_config,  # JSON-like config dict\n",
    ")  # Returns wrapped model AND optimizer\n",
    "```\n",
    "\n",
    "### Training Step\n",
    "\n",
    "```python\n",
    "# FSDP2 Approach\n",
    "loss = criterion(model(inputs), labels)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()           # Standard PyTorch backward\n",
    "optimizer.step()\n",
    "\n",
    "# DeepSpeed Approach\n",
    "loss = criterion(model(inputs), labels)\n",
    "model.backward(loss)      # DeepSpeed handles backward + zero_grad\n",
    "model.step()              # DeepSpeed handles optimizer step\n",
    "```\n",
    "\n",
    "### Checkpointing\n",
    "\n",
    "```python\n",
    "# FSDP2 Approach\n",
    "import torch.distributed.checkpoint as dcp\n",
    "dcp.save(state_dict={\"app\": AppState(model, optimizer)}, ...)\n",
    "\n",
    "# DeepSpeed Approach\n",
    "model.save_checkpoint(save_dir)  # Built-in method\n",
    "model.load_checkpoint(load_dir)  # Built-in method\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## `Step 1`: Environment Setup\n",
    "\n",
    "Let's verify our environment and install DeepSpeed. This tutorial requires:\n",
    "- A Ray cluster with GPU workers (this example uses 2 GPUs)\n",
    "- PyTorch 2.0+ with CUDA support\n",
    "- DeepSpeed library\n",
    "- Shared storage accessible from all workers (e.g., `/mnt/cluster_storage/`)\n",
    "\n",
    "When running on open-source Ray (without Anyscale), you'll need to:\n",
    "- Configure your Ray cluster manually\n",
    "- Set up NFS or cloud storage for checkpointing\n",
    "- Ensure PyTorch and DeepSpeed are installed on all worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Autoscaler status: 2026-02-01 17:27:29.505093 ========\n",
      "Node status\n",
      "---------------------------------------------------------------\n",
      "Active:\n",
      " 1 head_node\n",
      "Idle:\n",
      " 1 1xA10G:8CPU-32GB-2\n",
      " 1 1xA10G:8CPU-32GB-1\n",
      "Pending:\n",
      " (no pending nodes)\n",
      "Recent failures:\n",
      " (no failures)\n",
      "\n",
      "Resources\n",
      "---------------------------------------------------------------\n",
      "Total Usage:\n",
      " 0.0/16.0 CPU\n",
      " 0.0/2.0 GPU\n",
      " 0.0/2.0 anyscale/accelerator_shape:1xA10G\n",
      " 0.0/1.0 anyscale/cpu_only:true\n",
      " 0.0/1.0 anyscale/node-group:1xA10G:8CPU-32GB-1\n",
      " 0.0/1.0 anyscale/node-group:1xA10G:8CPU-32GB-2\n",
      " 0.0/1.0 anyscale/node-group:head_node\n",
      " 0.0/3.0 anyscale/provider:aws\n",
      " 0.0/3.0 anyscale/region:us-west-2\n",
      " 0B/96.00GiB memory\n",
      " 0B/26.62GiB object_store_memory\n",
      "\n",
      "Total Constraints:\n",
      " (no request_resources() constraints)\n",
      "Total Demands:\n",
      " (no resource demands)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Check Ray cluster status\n",
    "!ray status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccessfully registered `torch, torchvision` and 1 other packages to be installed on all cluster nodes.\u001b[0m\n",
      "\u001b[92mView and update dependencies here: https://console.anyscale.com/cld_g54aiirwj1s8t9ktgzikqur41k/prj_f1j47h9srml4cyg962id75ms2e/workspaces/expwrk_k1d9n8z4panjhy1yh7bqe1ywiz?workspace-tab=dependencies\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -q torch torchvision deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-01 17:27:33,244] [WARNING] [real_accelerator.py:209:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0+cu128\n",
      "Ray version: 2.49.1\n",
      "DeepSpeed version: 0.18.5\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "import ray\n",
    "import deepspeed\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Ray version: {ray.__version__}\")\n",
    "print(f\"DeepSpeed version: {deepspeed.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Ray Train V2 API\n",
    "import os\n",
    "os.environ[\"RAY_TRAIN_V2_ENABLED\"] = \"1\"\n",
    "\n",
    "# Standard imports\n",
    "import tempfile\n",
    "import uuid\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## `Step 2`: Model Definition (Same as FSDP2)\n",
    "\n",
    "We use the **same Vision Transformer model** as the FSDP2 tutorial. This makes it easy to compare the two approaches directly. The key difference is that DeepSpeed wraps your existing PyTorch model, so no model code changes are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing Vision Transformer model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 1,006,090 (1.01M)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import VisionTransformer\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "def init_model() -> torch.nn.Module:\n",
    "    \"\"\"Initialize a Vision Transformer model for FashionMNIST.\n",
    "    \n",
    "    This is IDENTICAL to the FSDP2 tutorial - no changes needed!\n",
    "    DeepSpeed wraps your existing PyTorch model.\n",
    "    \"\"\"\n",
    "    logger.info(\"Initializing Vision Transformer model...\")\n",
    "\n",
    "    model = VisionTransformer(\n",
    "        image_size=28,\n",
    "        patch_size=7,\n",
    "        num_layers=10,\n",
    "        num_heads=2,\n",
    "        hidden_dim=128,\n",
    "        mlp_dim=128,\n",
    "        num_classes=10,\n",
    "    )\n",
    "\n",
    "    # Modify for grayscale input\n",
    "    model.conv_proj = torch.nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=128,\n",
    "        kernel_size=7,\n",
    "        stride=7,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Verify model\n",
    "test_model = init_model()\n",
    "param_count = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"Model parameters: {param_count:,} ({param_count / 1e6:.2f}M)\")\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## `Step 3`: DeepSpeed Configuration\n",
    "\n",
    "**This is the key difference from FSDP2!** Instead of Python API calls, DeepSpeed uses a configuration dictionary (or JSON file). Every configuration option is highlighted and explained with a numbered comment; for example, \"[1].\"\n",
    "\n",
    "### Configuration Anatomy\n",
    "\n",
    "DeepSpeed configuration is declarative - you specify what you want, and DeepSpeed handles the implementation:\n",
    "\n",
    "```python\n",
    "deepspeed_config = {\n",
    "    # Optimizer configuration (DeepSpeed manages the optimizer)\n",
    "    \"optimizer\": {...},\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    \"scheduler\": {...},\n",
    "    \n",
    "    # Mixed precision settings\n",
    "    \"fp16\": {...} or \"bf16\": {...},\n",
    "    \n",
    "    # ZeRO optimization settings\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1|2|3,\n",
    "        \"offload_optimizer\": {...},  # CPU offloading\n",
    "        \"offload_param\": {...},      # Parameter offloading\n",
    "    },\n",
    "    \n",
    "    # Batch size configuration\n",
    "    \"train_micro_batch_size_per_gpu\": int,\n",
    "    \"gradient_accumulation_steps\": int,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSpeed Configuration:\n",
      "{\n",
      "  \"optimizer\": {\n",
      "    \"type\": \"Adam\",\n",
      "    \"params\": {\n",
      "      \"lr\": 0.001,\n",
      "      \"betas\": [\n",
      "        0.9,\n",
      "        0.999\n",
      "      ],\n",
      "      \"eps\": 1e-08,\n",
      "      \"weight_decay\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"scheduler\": {\n",
      "    \"type\": \"WarmupLR\",\n",
      "    \"params\": {\n",
      "      \"warmup_min_lr\": 0,\n",
      "      \"warmup_max_lr\": 0.001,\n",
      "      \"warmup_num_steps\": 100\n",
      "    }\n",
      "  },\n",
      "  \"fp16\": {\n",
      "    \"enabled\": true,\n",
      "    \"loss_scale\": 0,\n",
      "    \"loss_scale_window\": 1000,\n",
      "    \"initial_scale_power\": 16,\n",
      "    \"hysteresis\": 2,\n",
      "    \"min_loss_scale\": 1\n",
      "  },\n",
      "  \"zero_optimization\": {\n",
      "    \"stage\": 2,\n",
      "    \"allgather_bucket_size\": 200000000.0,\n",
      "    \"reduce_bucket_size\": 200000000.0,\n",
      "    \"overlap_comm\": true,\n",
      "    \"contiguous_gradients\": true\n",
      "  },\n",
      "  \"train_micro_batch_size_per_gpu\": 64,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"gradient_clipping\": 1.0,\n",
      "  \"steps_per_print\": 100,\n",
      "  \"wall_clock_breakdown\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_deepspeed_config(batch_size: int = 64, learning_rate: float = 0.001) -> dict:\n",
    "    \"\"\"Create DeepSpeed configuration for ZeRO Stage 2.\n",
    "    \n",
    "    We use Stage 2 here as it provides a good balance between\n",
    "    memory savings and communication overhead for our model size.\n",
    "    \n",
    "    For larger models (billions of parameters), use Stage 3.\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Micro batch size per GPU\n",
    "        learning_rate: Initial learning rate\n",
    "        \n",
    "    Returns:\n",
    "        DeepSpeed configuration dictionary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        # [1] Optimizer Configuration.\n",
    "        # DeepSpeed creates and manages the optimizer internally.\n",
    "        # This replaces: optimizer = Adam(model.parameters(), lr=...)\n",
    "        # ============================================================\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"Adam\",\n",
    "            \"params\": {\n",
    "                \"lr\": learning_rate,\n",
    "                \"betas\": [0.9, 0.999],\n",
    "                \"eps\": 1e-8,\n",
    "                \"weight_decay\": 0.0,\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # [2] Learning Rate Scheduler.\n",
    "        # Optional: DeepSpeed can manage LR scheduling.\n",
    "        # ==============================================\n",
    "        \"scheduler\": {\n",
    "            \"type\": \"WarmupLR\",\n",
    "            \"params\": {\n",
    "                \"warmup_min_lr\": 0,\n",
    "                \"warmup_max_lr\": learning_rate,\n",
    "                \"warmup_num_steps\": 100,\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # [3] Mixed Precision (FP16).\n",
    "        # Equivalent to FSDP2's MixedPrecisionPolicy.\n",
    "        # Provides ~2x memory reduction and faster computation.\n",
    "        # ======================================================\n",
    "        \"fp16\": {\n",
    "            \"enabled\": True,\n",
    "            \"loss_scale\": 0,              # Dynamic loss scaling\n",
    "            \"loss_scale_window\": 1000,\n",
    "            \"initial_scale_power\": 16,\n",
    "            \"hysteresis\": 2,\n",
    "            \"min_loss_scale\": 1,\n",
    "        },\n",
    "        \n",
    "        # [4] ZeRO Optimization.\n",
    "        # This is the core memory optimization feature.\n",
    "        # Stage 2 partitions optimizer states + gradients.\n",
    "        # =================================================\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 2,  # Partition optimizer states + gradients\n",
    "            \n",
    "            # CPU Offloading (similar to FSDP2's CPUOffloadPolicy)\n",
    "            # Uncomment to enable:\n",
    "            # \"offload_optimizer\": {\n",
    "            #     \"device\": \"cpu\",\n",
    "            #     \"pin_memory\": True,\n",
    "            # },\n",
    "            \n",
    "            # [5] Gradient bucketing for communication efficiency.\n",
    "            # ======================================================\n",
    "            \"allgather_bucket_size\": 2e8,\n",
    "            \"reduce_bucket_size\": 2e8,\n",
    "            \n",
    "            # [6] Overlap communication with computation.\n",
    "            # ===========================================\n",
    "            \"overlap_comm\": True,\n",
    "            \n",
    "            # [7] Contiguous gradients for efficiency.\n",
    "            # =========================================\n",
    "            \"contiguous_gradients\": True,\n",
    "        },\n",
    "        \n",
    "        # [8] Batch Size Configuration.\n",
    "        # DeepSpeed uses these to calculate effective batch size.\n",
    "        # =========================================================\n",
    "        \"train_micro_batch_size_per_gpu\": batch_size,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \n",
    "        # [9] Gradient Clipping.\n",
    "        # ======================\n",
    "        \"gradient_clipping\": 1.0,\n",
    "        \n",
    "        # [10] Logging.\n",
    "        # =============\n",
    "        \"steps_per_print\": 100,\n",
    "        \"wall_clock_breakdown\": False,\n",
    "    }\n",
    "\n",
    "# Preview the configuration\n",
    "import json\n",
    "print(\"DeepSpeed Configuration:\")\n",
    "print(json.dumps(get_deepspeed_config(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## `Step 4`: DeepSpeed Checkpointing\n",
    "\n",
    "DeepSpeed has **built-in checkpointing** that's simpler than FSDP2's DCP approach. The checkpointing methods are built into the DeepSpeed engine, so you don't need wrapper classes.\n",
    "\n",
    "### Key Differences from FSDP2\n",
    "\n",
    "| Feature | FSDP2 (DCP) | DeepSpeed |\n",
    "|---------|-------------|------------|\n",
    "| Save API | `dcp.save(state_dict, checkpoint_id)` | `model.save_checkpoint(dir)` |\n",
    "| Load API | `dcp.load(state_dict, checkpoint_id)` | `model.load_checkpoint(dir)` |\n",
    "| Format | `.distcp` shards | `mp_rank_*` directories |\n",
    "| Resharding | Automatic on load | Automatic on load |\n",
    "| Client code | Explicit wrapper needed | Built into engine |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train\n",
    "import torch.distributed as dist\n",
    "\n",
    "def save_deepspeed_checkpoint(\n",
    "    model,  # DeepSpeed engine\n",
    "    metrics: dict,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    \"\"\"Save DeepSpeed checkpoint and report to Ray Train.\n",
    "    \n",
    "    Unlike FSDP2's DCP, DeepSpeed has built-in checkpoint methods.\n",
    "    Each worker saves its shard, then we report to Ray Train.\n",
    "    \n",
    "    Args:\n",
    "        model: DeepSpeed engine (not raw PyTorch model)\n",
    "        metrics: Training metrics to report\n",
    "        epoch: Current epoch number\n",
    "    \"\"\"\n",
    "    logger.info(\"Saving DeepSpeed checkpoint...\")\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # DeepSpeed's built-in checkpoint method\n",
    "        # This saves optimizer states, model weights, and scheduler\n",
    "        model.save_checkpoint(\n",
    "            save_dir=temp_dir,\n",
    "            tag=f\"epoch_{epoch}\",\n",
    "            client_state={\"epoch\": epoch},  # Custom metadata\n",
    "        )\n",
    "        \n",
    "        # Synchronize all workers before reporting\n",
    "        dist.barrier()\n",
    "        \n",
    "        # Report checkpoint to Ray Train\n",
    "        checkpoint = ray.train.Checkpoint.from_directory(temp_dir)\n",
    "        ray.train.report(metrics, checkpoint=checkpoint)\n",
    "        \n",
    "    logger.info(f\"Checkpoint saved. Metrics: {metrics}\")\n",
    "\n",
    "\n",
    "def load_deepspeed_checkpoint(\n",
    "    model,  # DeepSpeed engine\n",
    "    checkpoint: ray.train.Checkpoint,\n",
    ") -> int:\n",
    "    \"\"\"Load DeepSpeed checkpoint for resuming training.\n",
    "    \n",
    "    Args:\n",
    "        model: DeepSpeed engine\n",
    "        checkpoint: Ray Train checkpoint object\n",
    "        \n",
    "    Returns:\n",
    "        Epoch number from checkpoint\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading DeepSpeed checkpoint...\")\n",
    "    \n",
    "    with checkpoint.as_directory() as checkpoint_dir:\n",
    "        # Find the checkpoint tag (e.g., \"epoch_4\")\n",
    "        import os\n",
    "        tags = [d for d in os.listdir(checkpoint_dir) \n",
    "                if d.startswith(\"epoch_\")]\n",
    "        if not tags:\n",
    "            raise ValueError(\"No checkpoint found\")\n",
    "        \n",
    "        latest_tag = sorted(tags)[-1]\n",
    "        \n",
    "        # DeepSpeed's built-in load method\n",
    "        _, client_state = model.load_checkpoint(\n",
    "            load_dir=checkpoint_dir,\n",
    "            tag=latest_tag,\n",
    "        )\n",
    "        \n",
    "    epoch = client_state.get(\"epoch\", 0) if client_state else 0\n",
    "    logger.info(f\"Loaded checkpoint from epoch {epoch}\")\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributed.checkpoint.state_dict import (\n",
    "    get_model_state_dict,\n",
    "    StateDictOptions\n",
    ")\n",
    "\n",
    "def save_model_for_inference(model, world_rank: int) -> None:\n",
    "    \"\"\"Save consolidated model for inference.\n",
    "    \n",
    "    For DeepSpeed, we can use the same approach as FSDP2:\n",
    "    gather weights to rank 0 and save a standard checkpoint.\n",
    "    \n",
    "    Note: For ZeRO-3, use `zero.GatheredParameters` context manager.\n",
    "    For ZeRO-1/2, the model weights are already complete on each rank.\n",
    "    \"\"\"\n",
    "    logger.info(\"Saving model for inference...\")\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        save_file = os.path.join(temp_dir, \"full-model.pt\")\n",
    "        \n",
    "        # For ZeRO Stage 2, weights are complete on each rank\n",
    "        # We just need rank 0 to save\n",
    "        if world_rank == 0:\n",
    "            # Get the underlying PyTorch module\n",
    "            state_dict = model.module.state_dict()\n",
    "            torch.save(state_dict, save_file)\n",
    "            logger.info(f\"Saved model to {save_file}\")\n",
    "            checkpoint = ray.train.Checkpoint.from_directory(temp_dir)\n",
    "        else:\n",
    "            checkpoint = None\n",
    "        \n",
    "        # Synchronize before reporting\n",
    "        dist.barrier()\n",
    "        \n",
    "        ray.train.report({}, checkpoint=checkpoint, checkpoint_dir_name=\"full_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## `Step 5`: Training Function\n",
    "\n",
    "Here's the main training function. Notice the key differences from FSDP2. Every difference is highlighted and explained with a numbered comment; for example, \"[1].\"\n",
    "\n",
    "### Key Differences from FSDP2:\n",
    "\n",
    "1. **[1] No `prepare_model()`**: DeepSpeed handles model distribution internally\n",
    "2. **[2] `deepspeed.initialize()`**: Creates the DeepSpeed engine and manages the optimizer\n",
    "3. **[3] `model.backward(loss)`**: Instead of `loss.backward()` - DeepSpeed handles backward pass and zero_grad\n",
    "4. **[4] `model.step()`**: Instead of `optimizer.step()` - DeepSpeed handles optimizer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train.torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import deepspeed\n",
    "\n",
    "def train_func(config):\n",
    "    \"\"\"DeepSpeed training function for Ray Train.\n",
    "    \n",
    "    Key differences from FSDP2:\n",
    "    - Use deepspeed.initialize() instead of fully_shard()\n",
    "    - DeepSpeed manages optimizer internally\n",
    "    - Use model.backward(loss) instead of loss.backward()\n",
    "    - Use model.step() instead of optimizer.step()\n",
    "    \"\"\"\n",
    "    # ===== Model Setup =====\n",
    "    model = init_model()\n",
    "    \n",
    "    # Get DeepSpeed configuration\n",
    "    ds_config = get_deepspeed_config(\n",
    "        batch_size=config.get('batch_size', 64),\n",
    "        learning_rate=config.get('learning_rate', 0.001),\n",
    "    )\n",
    "    \n",
    "    # [1] DeepSpeed Initialization.\n",
    "    # This replaces:\n",
    "    #   - model.to(device)\n",
    "    #   - fully_shard(model, ...)\n",
    "    #   - optimizer = Adam(model.parameters())\n",
    "    # DeepSpeed handles model distribution and optimizer creation internally.\n",
    "    # ======================================================================\n",
    "    model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "        model=model,\n",
    "        config=ds_config,\n",
    "        model_parameters=model.parameters(),\n",
    "    )\n",
    "    \n",
    "    # Get the device from DeepSpeed\n",
    "    device = model_engine.device\n",
    "    \n",
    "    # ===== Loss Function =====\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    # ===== Checkpoint Loading =====\n",
    "    start_epoch = 0\n",
    "    loaded_checkpoint = ray.train.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        start_epoch = load_deepspeed_checkpoint(model_engine, loaded_checkpoint) + 1\n",
    "        logger.info(f\"Resuming from epoch {start_epoch}\")\n",
    "    \n",
    "    # [2] Data Loading.\n",
    "    # NOTE: With DeepSpeed, DON'T use ray.train.torch.prepare_data_loader()\n",
    "    # DeepSpeed handles data distribution differently - use DistributedSampler directly.\n",
    "    # ==================================================================================\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    data_dir = os.path.join(tempfile.gettempdir(), \"data\")\n",
    "    train_data = FashionMNIST(\n",
    "        root=data_dir, train=True, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    # Create sampler for distributed training\n",
    "    sampler = torch.utils.data.DistributedSampler(\n",
    "        train_data,\n",
    "        num_replicas=ray.train.get_context().get_world_size(),\n",
    "        rank=ray.train.get_context().get_world_rank(),\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=config.get('batch_size', 64),\n",
    "        sampler=sampler,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    # ===== Training Context =====\n",
    "    world_rank = ray.train.get_context().get_world_rank()\n",
    "    run_name = ray.train.get_context().get_experiment_name()\n",
    "    \n",
    "    # ===== Memory Profiling =====\n",
    "    torch.cuda.memory._record_memory_history(max_entries=100000)\n",
    "    \n",
    "    # ===== Training Loop =====\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    epochs = config.get('epochs', 5)\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        sampler.set_epoch(epoch)  # For proper shuffling\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # IMPORTANT: Cast inputs to FP16 when using mixed precision\n",
    "            # DeepSpeed converts model weights to FP16, so inputs must match\n",
    "            if model_engine.fp16_enabled():\n",
    "                images = images.half()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model_engine(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # [3] Backward pass - DeepSpeed style!\n",
    "            # This replaces:\n",
    "            #   optimizer.zero_grad()\n",
    "            #   loss.backward()\n",
    "            #   optimizer.step()\n",
    "            # DeepSpeed handles all three operations internally.\n",
    "            # ====================================================\n",
    "            model_engine.backward(loss)\n",
    "            model_engine.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Report metrics and save checkpoint\n",
    "        avg_loss = running_loss / num_batches\n",
    "        metrics = {\"loss\": avg_loss, \"epoch\": epoch}\n",
    "        save_deepspeed_checkpoint(model_engine, metrics, epoch)\n",
    "        \n",
    "        if world_rank == 0:\n",
    "            logger.info(f\"Epoch {epoch}: loss={avg_loss:.4f}\")\n",
    "    \n",
    "    # ===== Save Memory Snapshot =====\n",
    "    try:\n",
    "        snapshot_path = f\"/mnt/cluster_storage/{run_name}/rank{world_rank}_memory_snapshot.pickle\"\n",
    "        torch.cuda.memory._dump_snapshot(snapshot_path)\n",
    "        logger.info(f\"Saved memory snapshot to {snapshot_path}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not save memory snapshot: {e}\")\n",
    "    finally:\n",
    "        torch.cuda.memory._record_memory_history(enabled=None)\n",
    "    \n",
    "    # ===== Save Final Model =====\n",
    "    save_model_for_inference(model_engine, world_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## `Step 6`: Launch Distributed Training\n",
    "\n",
    "The Ray Train setup is **almost identical** to FSDP2. The main difference is that we don't need any special FSDP-specific configuration - DeepSpeed handles everything through its config dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: deepspeed_mnist_34e40726\n",
      "Workers: 2\n",
      "Epochs: 5\n"
     ]
    }
   ],
   "source": [
    "import ray.train\n",
    "import ray.train.torch\n",
    "\n",
    "# Scaling configuration - same as FSDP2!\n",
    "scaling_config = ray.train.ScalingConfig(\n",
    "    num_workers=2,\n",
    "    use_gpu=True,\n",
    ")\n",
    "\n",
    "# Training hyperparameters\n",
    "train_loop_config = {\n",
    "    \"epochs\": 5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "}\n",
    "\n",
    "# Unique experiment name\n",
    "experiment_name = f\"deepspeed_mnist_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Run configuration\n",
    "run_config = ray.train.RunConfig(\n",
    "    storage_path=\"/mnt/cluster_storage/\",\n",
    "    name=experiment_name,\n",
    "    failure_config=ray.train.FailureConfig(max_failures=1),\n",
    ")\n",
    "\n",
    "print(f\"Experiment: {experiment_name}\")\n",
    "print(f\"Workers: {scaling_config.num_workers}\")\n",
    "print(f\"Epochs: {train_loop_config['epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-01 17:27:38,747\tINFO worker.py:1771 -- Connecting to existing Ray cluster at address: 10.0.127.246:6379...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DeepSpeed training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-01 17:27:38,758\tINFO worker.py:1942 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-lehzcwqlg8w8ui213vjr5igw7j.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2026-02-01 17:27:38,761\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_53c05f65135986a0fc4a81b263296a532a2a3021.zip' (0.61MiB) to Ray cluster...\n",
      "2026-02-01 17:27:38,765\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_53c05f65135986a0fc4a81b263296a532a2a3021.zip'.\n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m [State Transition] INITIALIZING -> SCHEDULING.\n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'GPU': 1}] * 2\n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Initializing Vision Transformer model...\n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m Started training worker group of size 2: \n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m - (ip=10.0.102.145, pid=6819) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m - (ip=10.0.82.245, pid=7619) world_rank=1, local_rank=0, node_rank=1\n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m [State Transition] SCHEDULING -> RUNNING.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m [2026-02-01 17:27:51,599] [WARNING] [lr_schedules.py:690:get_lr] Attempting to get learning rate from scheduler before it has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Before initializing optimizer states\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m MA 0.0 GB         Max_MA 0.0 GB         CA 0.02 GB         Max_CA 0 GB \n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m CPU Virtual Memory:  used = 3.46 GB, percent = 11.2%\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m After initializing optimizer states\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m MA 0.0 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m CPU Virtual Memory:  used = 3.46 GB, percent = 11.2%\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m After initializing ZeRO optimizer\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m MA 0.0 GB         Max_MA 0.0 GB         CA 0.02 GB         Max_CA 0 GB \n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m CPU Virtual Memory:  used = 3.46 GB, percent = 11.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +49s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Saving DeepSpeed checkpoint...\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m /tmp/ray/session_2026-02-01_16-45-46_338165_2431/runtime_resources/pip/ae159e3c0955bfdbdfe1ff48e527ea80167311c2/virtualenv/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:83: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m   return func(*args, **kwargs)\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m [rank0]:[W201 17:28:55.997155180 ProcessGroupNCCL.cpp:5138] Guessing device ID based on global rank. This can cause a hang if rank to GPU mapping is heterogeneous. You can specify device_id in init_process_group()\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Initializing Vision Transformer model...\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-28-55.856021)\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.7980480722781184, 'epoch': 0}\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Epoch 0: loss=0.8043\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Saving DeepSpeed checkpoint...\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m [rank1]:[W201 17:28:55.546105093 ProcessGroupNCCL.cpp:5138] Guessing device ID based on global rank. This can cause a hang if rank to GPU mapping is heterogeneous. You can specify device_id in init_process_group()\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-28-55.856021)\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.8042903159981343, 'epoch': 0}\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-29-59.126707)\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.6282549046758396, 'epoch': 1}\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Epoch 1: loss=0.6318\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Saving DeepSpeed checkpoint...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-29-59.126707)\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.6317840120685634, 'epoch': 1}\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-31-02.544201)\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.5548015884583778, 'epoch': 2}\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Epoch 2: loss=0.5548\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Saving DeepSpeed checkpoint...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-31-02.544201)\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.5538710951381486, 'epoch': 2}\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-32-05.953257)\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.5092520317289112, 'epoch': 3}\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Epoch 3: loss=0.5094\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Saving DeepSpeed checkpoint...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-32-05.953257)\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.5094384232055403, 'epoch': 3}\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-33-09.432923)\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.47734192805503733, 'epoch': 4}\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Epoch 4: loss=0.4793\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Saved memory snapshot to /mnt/cluster_storage/deepspeed_mnist_34e40726/rank1_memory_snapshot.pickle\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Saving DeepSpeed checkpoint...\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/checkpoint_2026-02-01_17-33-09.432923)\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint saved. Metrics: {'loss': 0.4793288631479877, 'epoch': 4}\n",
      "\u001b[36m(RayTrainWorker pid=7619, ip=10.0.82.245)\u001b[0m Saving model for inference...\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Saved model to /tmp/tmpybphe8kx/full-model.pt\n",
      "\u001b[36m(RayTrainWorker pid=6819, ip=10.0.102.145)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/full_model)\n",
      "\u001b[36m(TrainController pid=18125)\u001b[0m [State Transition] RUNNING -> FINISHED.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n",
      "Final checkpoint: Checkpoint(filesystem=local, path=/mnt/cluster_storage/deepspeed_mnist_34e40726/full_model)\n"
     ]
    }
   ],
   "source": [
    "# Create and run trainer\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    train_loop_config=train_loop_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "print(\"Starting DeepSpeed training...\")\n",
    "result = trainer.fit()\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Final checkpoint: {result.checkpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## `Step 7`: Inspect Training Artifacts\n",
    "\n",
    "DeepSpeed checkpoint structure differs from FSDP2's DCP format:\n",
    "\n",
    "```\n",
    "/mnt/cluster_storage/{experiment_name}/\n",
    "â”œâ”€â”€ checkpoint_*/\n",
    "â”‚   â””â”€â”€ epoch_N/                  # DeepSpeed checkpoint tag\n",
    "â”‚       â”œâ”€â”€ mp_rank_00_model_states.pt  # Model states for rank 0\n",
    "â”‚       â”œâ”€â”€ mp_rank_01_model_states.pt  # Model states for rank 1\n",
    "â”‚       â”œâ”€â”€ zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
    "â”‚       â””â”€â”€ zero_pp_rank_1_mp_rank_01_optim_states.pt\n",
    "â”œâ”€â”€ full_model/\n",
    "â”‚   â””â”€â”€ full-model.pt\n",
    "â””â”€â”€ rank*_memory_snapshot.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts in /mnt/cluster_storage/deepspeed_mnist_34e40726/:\n",
      "  ğŸ“„ rank1_memory_snapshot.pickle (18.76 MB)\n",
      "  ğŸ“ checkpoint_2026-02-01_17-32-05.953257/\n",
      "      â””â”€â”€ epoch_3\n",
      "      â””â”€â”€ latest\n",
      "      â””â”€â”€ zero_to_fp32.py\n",
      "  ğŸ“„ rank0_memory_snapshot.pickle (18.77 MB)\n",
      "  ğŸ“„ checkpoint_manager_snapshot.json (0.00 MB)\n",
      "  ğŸ“„ .validate_storage_marker (0.00 MB)\n",
      "  ğŸ“ checkpoint_2026-02-01_17-29-59.126707/\n",
      "      â””â”€â”€ latest\n",
      "      â””â”€â”€ zero_to_fp32.py\n",
      "      â””â”€â”€ epoch_1\n",
      "  ğŸ“ checkpoint_2026-02-01_17-33-09.432923/\n",
      "      â””â”€â”€ epoch_4\n",
      "      â””â”€â”€ latest\n",
      "      â””â”€â”€ zero_to_fp32.py\n",
      "  ğŸ“ full_model/\n",
      "  ğŸ“ checkpoint_2026-02-01_17-31-02.544201/\n",
      "      â””â”€â”€ epoch_2\n",
      "      â””â”€â”€ latest\n",
      "      â””â”€â”€ zero_to_fp32.py\n",
      "  ğŸ“ checkpoint_2026-02-01_17-28-55.856021/\n",
      "      â””â”€â”€ epoch_0\n",
      "      â””â”€â”€ latest\n",
      "      â””â”€â”€ zero_to_fp32.py\n"
     ]
    }
   ],
   "source": [
    "# List training artifacts\n",
    "storage_path = f\"/mnt/cluster_storage/{experiment_name}/\"\n",
    "print(f\"Artifacts in {storage_path}:\")\n",
    "for item in os.listdir(storage_path):\n",
    "    full_path = os.path.join(storage_path, item)\n",
    "    if os.path.isdir(full_path):\n",
    "        print(f\"  ğŸ“ {item}/\")\n",
    "        # Show DeepSpeed checkpoint structure\n",
    "        if item.startswith(\"checkpoint\"):\n",
    "            for sub in os.listdir(full_path)[:3]:  # Limit output\n",
    "                print(f\"      â””â”€â”€ {sub}\")\n",
    "    else:\n",
    "        size_mb = os.path.getsize(full_path) / (1024 * 1024)\n",
    "        print(f\"  ğŸ“„ {item} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## `Step 8`: Load Model for Inference\n",
    "\n",
    "Loading for inference is **identical** to FSDP2 - we saved a standard PyTorch checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /mnt/cluster_storage/deepspeed_mnist_34e40726/full_model/full-model.pt\n"
     ]
    }
   ],
   "source": [
    "# Path to saved model\n",
    "PATH_TO_FULL_MODEL = f\"/mnt/cluster_storage/{experiment_name}/full_model/full-model.pt\"\n",
    "print(f\"Loading model from: {PATH_TO_FULL_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing Vision Transformer model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "inference_model = init_model()\n",
    "state_dict = torch.load(PATH_TO_FULL_MODEL, map_location='cpu', weights_only=True)\n",
    "inference_model.load_state_dict(state_dict)\n",
    "inference_model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions:\n",
      "--------------------------------------------------\n",
      "âœ— Sample 0: predicted=Pullover     actual=Ankle boot\n",
      "âœ“ Sample 1: predicted=Pullover     actual=Pullover\n",
      "âœ— Sample 2: predicted=Bag          actual=Trouser\n",
      "âœ— Sample 3: predicted=T-shirt/top  actual=Trouser\n",
      "âœ— Sample 4: predicted=Pullover     actual=Shirt\n",
      "âœ— Sample 5: predicted=Shirt        actual=Trouser\n",
      "âœ“ Sample 6: predicted=Coat         actual=Coat\n",
      "âœ— Sample 7: predicted=Coat         actual=Shirt\n",
      "âœ— Sample 8: predicted=Pullover     actual=Sandal\n",
      "âœ— Sample 9: predicted=Pullover     actual=Sneaker\n",
      "--------------------------------------------------\n",
      "Accuracy on samples: 2/10 (20%)\n"
     ]
    }
   ],
   "source": [
    "# Test inference\n",
    "transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "test_data = FashionMNIST(root=\"/tmp\", train=False, download=True, transform=transform)\n",
    "\n",
    "CLASSES = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "print(\"\\nSample predictions:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for i in range(10):\n",
    "        image = test_data.data[i].reshape(1, 1, 28, 28).float()\n",
    "        output = inference_model(image)\n",
    "        predicted = output.argmax().item()\n",
    "        actual = test_data.targets[i].item()\n",
    "        correct += (predicted == actual)\n",
    "        \n",
    "        status = \"âœ“\" if predicted == actual else \"âœ—\"\n",
    "        print(f\"{status} Sample {i}: predicted={CLASSES[predicted]:12s} actual={CLASSES[actual]}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Accuracy on samples: {correct}/10 ({correct*10}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Summary: FSDP2 vs DeepSpeed\n",
    "\n",
    "### Side-by-Side Comparison\n",
    "\n",
    "| Aspect | FSDP2 | DeepSpeed |\n",
    "|--------|-------|----------|\n",
    "| **Setup** | `fully_shard(model, mesh, ...)` | `deepspeed.initialize(model, config)` |\n",
    "| **Optimizer** | User creates separately | Managed by DeepSpeed |\n",
    "| **Training Step** | `loss.backward()` | `model.backward(loss)` |\n",
    "| **Optimizer Step** | `optimizer.step()` | `model.step()` |\n",
    "| **Configuration** | Python API | JSON/dict config |\n",
    "| **Checkpointing** | PyTorch DCP | Built-in methods |\n",
    "| **Data Loader** | `prepare_data_loader()` | Manual `DistributedSampler` |\n",
    "\n",
    "### When to Use Which?\n",
    "\n",
    "**Choose FSDP2 when:**\n",
    "- You want native PyTorch integration\n",
    "- You're using PyTorch's ecosystem (DTensor, etc.)\n",
    "- You prefer Python API over config files\n",
    "- You need fine-grained control over sharding\n",
    "\n",
    "**Choose DeepSpeed when:**\n",
    "- Training very large models (billions of parameters)\n",
    "- You need advanced CPU/NVMe offloading\n",
    "- Using HuggingFace Transformers (great integration)\n",
    "- You want battle-tested LLM training recipes\n",
    "- You need fused optimizers (FusedAdam, etc.)\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Both achieve similar memory savings** through different APIs\n",
    "2. **Ray Train works seamlessly** with both approaches\n",
    "3. **Model definition stays the same** - only the wrapping changes\n",
    "4. **Inference is identical** - save a standard PyTorch checkpoint\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [DeepSpeed Documentation](https://www.deepspeed.ai/)\n",
    "- [DeepSpeed ZeRO Tutorial](https://www.deepspeed.ai/tutorials/zero/)\n",
    "- [Ray Train DeepSpeed Guide](https://docs.ray.io/en/latest/train/deepspeed.html)\n",
    "- [Ray Train DeepSpeed Example](https://docs.ray.io/en/latest/train/examples/deepspeed/deepspeed_example.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 10. Bonus: ZeRO Stage 3 Configuration\n",
    "\n",
    "For reference, here's how to configure ZeRO Stage 3 (equivalent to FSDP2 with `reshard_after_forward=True`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeRO Stage 3 Configuration (for large models):\n",
      "{\n",
      "  \"optimizer\": {\n",
      "    \"type\": \"AdamW\",\n",
      "    \"params\": {\n",
      "      \"lr\": 0.001,\n",
      "      \"weight_decay\": 0.01\n",
      "    }\n",
      "  },\n",
      "  \"fp16\": {\n",
      "    \"enabled\": true\n",
      "  },\n",
      "  \"zero_optimization\": {\n",
      "    \"stage\": 3,\n",
      "    \"offload_optimizer\": {\n",
      "      \"device\": \"cpu\",\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"offload_param\": {\n",
      "      \"device\": \"cpu\",\n",
      "      \"pin_memory\": true\n",
      "    },\n",
      "    \"overlap_comm\": true,\n",
      "    \"contiguous_gradients\": true,\n",
      "    \"reduce_bucket_size\": 50000000.0,\n",
      "    \"stage3_prefetch_bucket_size\": 50000000.0,\n",
      "    \"stage3_param_persistence_threshold\": 100000.0,\n",
      "    \"stage3_gather_16bit_weights_on_model_save\": true\n",
      "  },\n",
      "  \"train_micro_batch_size_per_gpu\": 64,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"gradient_clipping\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_zero3_config(batch_size: int = 64, learning_rate: float = 0.001) -> dict:\n",
    "    \"\"\"ZeRO Stage 3 configuration with CPU offloading.\n",
    "    \n",
    "    This is the maximum memory optimization - equivalent to:\n",
    "    - FSDP2 with reshard_after_forward=True\n",
    "    - FSDP2 with CPUOffloadPolicy()\n",
    "    - FSDP2 with MixedPrecisionPolicy()\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"AdamW\",\n",
    "            \"params\": {\"lr\": learning_rate, \"weight_decay\": 0.01}\n",
    "        },\n",
    "        \n",
    "        \"fp16\": {\"enabled\": True},\n",
    "        \n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 3,  # Full parameter partitioning!\n",
    "            \n",
    "            # CPU offloading for optimizer states\n",
    "            \"offload_optimizer\": {\n",
    "                \"device\": \"cpu\",\n",
    "                \"pin_memory\": True,\n",
    "            },\n",
    "            \n",
    "            # CPU offloading for parameters\n",
    "            \"offload_param\": {\n",
    "                \"device\": \"cpu\",\n",
    "                \"pin_memory\": True,\n",
    "            },\n",
    "            \n",
    "            # Memory optimization flags\n",
    "            \"overlap_comm\": True,\n",
    "            \"contiguous_gradients\": True,\n",
    "            \"reduce_bucket_size\": 5e7,\n",
    "            \"stage3_prefetch_bucket_size\": 5e7,\n",
    "            \"stage3_param_persistence_threshold\": 1e5,\n",
    "            \n",
    "            # Gather weights for saving/loading\n",
    "            \"stage3_gather_16bit_weights_on_model_save\": True,\n",
    "        },\n",
    "        \n",
    "        \"train_micro_batch_size_per_gpu\": batch_size,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"gradient_clipping\": 1.0,\n",
    "    }\n",
    "\n",
    "print(\"ZeRO Stage 3 Configuration (for large models):\")\n",
    "print(json.dumps(get_zero3_config(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next Steps for the Blog:**\n",
    "\n",
    "1. Run both notebooks on the same cluster\n",
    "2. Compare memory usage profiles\n",
    "3. Benchmark training throughput\n",
    "4. Try with larger models (GPT-2, BERT)\n",
    "\n",
    "Both FSDP2 and DeepSpeed are excellent choices for distributed training. The best choice depends on your specific use case, existing tooling, and team familiarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
