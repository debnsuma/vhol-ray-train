{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Distributed Training with PyTorch and Ray Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through the basics of distributed training with Ray Train and PyTorch.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b> Here is the roadmap for this notebook </b>\n",
    "\n",
    "<ol>\n",
    "  <li>When to use Ray Train</li>\n",
    "  <li>Single GPU Training with PyTorch</li>\n",
    "  <li>Distributed Data Parallel Training with Ray Train and PyTorch</li>\n",
    "  <li>Integrating Ray Train with Ray Data</li>\n",
    "  <li>Fault tolerance in Ray Train</li>\n",
    "  <li>Ray Train in Production</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os   \n",
    "import tempfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "import ray\n",
    "from ray.train import ScalingConfig, RunConfig\n",
    "from ray.train.torch import TorchTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. When to use Ray Train\n",
    "\n",
    "Use Ray Train when you face one of the following challenges:\n",
    "\n",
    "|Challenge|Detail|Solution|\n",
    "|---|---|---|\n",
    "|Need to speed up or scale up training| Training jobs might take a long time to complete, or require a lot of compute | Ray Train provides a distributed training framework that allows engineers to scale training jobs to multiple GPUs |\n",
    "|Minimize overhead of setting up distributed training| Engineers need to manage the underlying infrastructure | Ray Train handles the underlying infrastructure via Ray's autoscaling |\n",
    "|Achieve observability| Engineers need to connect to different nodes and GPUs to find the root cause of failures, fetch logs, traces, etc | Ray Train provides observability via Ray's dashboard, metrics, and traces that allow engineers to monitor the training job |\n",
    "|Ensure reliable training| Training jobs can fail due to hardware failures, network issues, or other unexpected events | Ray Train provides fault tolerance via checkpointing, automatic retries, and the ability to resume training from the last checkpoint |\n",
    "|Avoid significant code rewrite| Engineers might need to fully rewrite their training loop to support distributed training | Ray Train provides a suite of integrations with the PyTorch ecosystem, Tree-based methods (XGB, LGBM), and more to minimize the amount of code changes needed |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single GPU Training with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by fitting a `ResNet18` model to an `MNIST` dataset. Conceptually we will follow the below recipe presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/single_gpu_pytorch_v3.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|An overview of the single GPU training process. At a high level, here is how training loop in PyTorch looks like. The key stages include loading the dataset; run the training on mini-batches on a single GPU; saving the model checkpoint to the persistent storage.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop_torch(num_epochs: int = 2, batch_size: int = 128, local_path: str = \"./checkpoints\"):\n",
    "\n",
    "    # Model, Loss, Optimizer\n",
    "    criterion = CrossEntropyLoss()\n",
    "    model = load_model_torch()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Load the data loader\n",
    "    data_loader = build_data_loader_torch(batch_size=batch_size)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in data_loader:\n",
    "\n",
    "            # Move the data to the GPU\n",
    "            images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "        # Report the metrics\n",
    "        metrics = report_metrics_torch(loss=loss, epoch=epoch)\n",
    "        \n",
    "        # Save the checkpoint and metrics\n",
    "        Path(local_path).mkdir(parents=True, exist_ok=True)\n",
    "        save_checkpoint_and_metrics_torch(metrics=metrics, model=model, local_path=local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Quick notes:\n",
    "\n",
    "<ul>\n",
    "    <li><code>report_metrics_torch</code> and <code>save_checkpoint_and_metrics_torch</code> are defined below,</li>\n",
    "    <li><code>local_path</code> is used for checkpointing. (default) Current working directory simply points to the notebook location (check <code>pwd</code> below).</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ray/default_cld_g54aiirwj1s8t9ktgzikqur41k/vhol-ray-train/02-ddp-pytorch-ray\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Build model and load it on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build [Resnet18](https://pytorch.org/vision/main/models/resnet.html#resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_resnet18():\n",
    "    model = resnet18(num_classes=10)\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        in_channels=1, # grayscale MNIST images\n",
    "        out_channels=64,\n",
    "        kernel_size=(7, 7),\n",
    "        stride=(2, 2),\n",
    "        padding=(3, 3),\n",
    "        bias=False,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "resnet18's <code>model.conv1</code> has <code>in_channels=3</code> by default. Here, we work with the <a href=\"https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html#mnist\" target=\"_blank\">MNIST</a> grayscale images, thus <code>in_channels=1</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load the model on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_torch() -> torch.nn.Module:\n",
    "    model = build_resnet18()\n",
    "\n",
    "    # move to the GPU device\n",
    "    model.to(\"cuda\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(root=\"./data\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\n",
      "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\n",
      "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/MNIST/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display 9 example (image, target) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = np.random.randint(0, len(dataset.data))\n",
    "    img, label = dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a DataLoader to apply transformations and load data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_data_loader_torch(batch_size: int) -> torch.utils.data.DataLoader:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Create metrics and checkpoiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and report the metrics using a simple print statement, and also save them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def report_metrics_torch(loss: torch.Tensor, epoch: int) -> None:\n",
    "    metrics = {\"loss\": loss.item(), \"epoch\": epoch}\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the checkpoint in a previously defined local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_torch(metrics: dict[str, float], model: torch.nn.Module, local_path: str) -> None:\n",
    "\n",
    "    # Save the metrics\n",
    "    with open(os.path.join(local_path, \"metrics.csv\"), \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(metrics.values())\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = os.path.join(local_path, \"model.pt\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Run the training loop\n",
    "Schedule the training loop on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now(datetime.UTC).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "local_path = f\"/mnt/local_storage/single_gpu_mnist/torch_{timestamp}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Note about Anyscale storage options</b>\n",
    "\n",
    "In this example <code>local_path</code> points to the Anyscale's <a href=\"https://docs.anyscale.com/configuration/storage/#local-storage-for-a-node\" target=\"_blank\">local storage</a>. It's a convenient and quick access location for this basic example.\n",
    "\n",
    "* Anyscale provides each node with its own volume and disk and doesnâ€™t share them with other nodes.\n",
    "* Local storage is very fast - Anyscale supports the Non-Volatile Memory Express (NVMe) interface.\n",
    "* This is not a persisent storage, Anyscale deletes data in the local storage after instances are terminated. \n",
    "\n",
    "Read more about available <a href=\"https://docs.anyscale.com/configuration/storage\" target=\"_blank\">storage</a> options.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.23444394767284393, 'epoch': 0}\n",
      "{'loss': 0.19371330738067627, 'epoch': 1}\n",
      "{'loss': 0.14566871523857117, 'epoch': 2}\n"
     ]
    }
   ],
   "source": [
    "train_loop_torch(\n",
    "    num_epochs=3,\n",
    "    local_path=local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the produced checkpoints and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 43736\n",
      "-rw-r--r-- 1 ray users       69 Jan 26 23:20 metrics.csv\n",
      "-rw-r--r-- 1 ray users 44773963 Jan 26 23:20 model.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -l {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.193713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145669</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  epoch\n",
       "0  0.234444      0\n",
       "1  0.193713      1\n",
       "2  0.145669      2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.read_csv(\n",
    "    os.path.join(local_path, \"metrics.csv\"),\n",
    "    header=None,\n",
    "    names=[\"loss\", \"epoch\"],\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Use checkpointed model to generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model checkpoint to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = build_resnet18()\n",
    "loaded_model.load_state_dict(torch.load(os.path.join(local_path, \"model.pt\")))\n",
    "loaded_model.to(\"cuda\")\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions on randomly selected 9 images rom the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = np.random.randint(0, len(dataset.data))\n",
    "    img, label = dataset[sample_idx]\n",
    "    normalized_img = Normalize((0.5,), (0.5,))(ToTensor()(img))\n",
    "    normalized_img = normalized_img.to(\"cuda\")\n",
    "\n",
    "    # use loaded model to generate preds\n",
    "    with torch.no_grad():        \n",
    "        prediction = loaded_model(normalized_img.unsqueeze(0)).argmax().cpu()\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"label: {label}; pred: {int(prediction)}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distributed Data Parallel Training with Ray Train and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture overview\n",
    "\n",
    "Ray Train's architecture is based on the following components:\n",
    "1. A Ray Train Controller/Driver that schedules the training workers, handles errors and manages checkpoints\n",
    "2. Ray Train Worker executing the training code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key API concepts\n",
    "\n",
    "Below are the key API concepts of Ray Train:\n",
    "\n",
    "1. `train_loop_per_worker`: This is the main function that contains your model training logic.\n",
    "2. `ScalingConfig`: This is used to specify the number of workers and compute resources (CPUs or GPUs, TPUs).\n",
    "3. `Trainer`: This is used to manage the training process.\n",
    "4. `Trainer.fit()`: This is used to start the training process.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/overview.png\" width=\"700\" loading=\"lazy\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the diagram showing how the key components usually work together.\n",
    "\n",
    "- The Train Controller/Driver is constantly performing health checks on the Train workers.\n",
    "- The Train workers are running the training loop and at a particular frequency checkpointing the model to a persistent storage.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-train-deep-dive/ray_train_detailed_architecture.png\" width=\"800\" loading=\"lazy\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the case where we have a very large dataset of images that would take a long time to train on a single GPU. We would now like to scale this training job to run on multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "|<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/multi_gpu_pytorch_v4.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Schematic overview of DistributedDataParallel (DDP) training: (1) the model is replicated from the <code>GPU rank 0</code> to all other workers; (2) each worker receives a shard of the dataset and processes a mini-batch; (3) during the backward pass, gradients are averaged across GPUs; (4) checkpoint and metrics from rank 0 GPU are saved to the persistent storage.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Here is a migration roadmap: from PyTorch DDP to PyTorch with Ray Train</b>\n",
    "\n",
    "<ol>\n",
    "    <li>Configure scale and GPUs</li>\n",
    "    <li>Migrate the model to Ray Train</li>\n",
    "    <li>Migrate the dataset to Ray Train</li>\n",
    "    <li>Build checkpoints and metrics reporting</li>\n",
    "    <li>Configure persistent storage</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Overview of the training loop in Ray Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this data-parallel training loop will look like with Ray Train and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_ray_train(config: dict):  # pass in hyperparameters in config\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Use Ray Train to wrap the model with DistributedDataParallel\n",
    "    model = load_model_ray_train()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Calculate the batch size for each worker\n",
    "    global_batch_size = config[\"global_batch_size\"]\n",
    "    world_size = ray.train.get_context().get_world_size()\n",
    "    batch_size = global_batch_size // world_size\n",
    "    print(f\"{world_size=}\\n{batch_size=}\")\n",
    "\n",
    "    # Use Ray Train to wrap the data loader as a DistributedSampler\n",
    "    data_loader = build_data_loader_ray_train(batch_size=batch_size)\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "\n",
    "        # Ensure data is on the correct device\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        # images, labels are now sharded across the workers\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # gradients are now accumulated across the workers\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Use Ray Train to report metrics\n",
    "        metrics = print_metrics_ray_train(loss, epoch)\n",
    "\n",
    "        # Use Ray Train to save checkpoint and metrics\n",
    "        save_checkpoint_and_metrics_ray_train(model, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Main training loop</b>\n",
    "<ul>\n",
    "  <li><strong>global_batch_size</strong>: the total number of samples processed in a single training step of the entire training job.\n",
    "    <ul>\n",
    "      <li>It's estimated like this: <code>batch size * DDP workers * gradient accumulation steps</code>.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>Notice that images and labels are no longer manually moved to device (<code>images.to(\"cuda\")</code>). This is done by \n",
    "    <a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_data_loader.html#ray-train-torch-prepare-data-loader\" target=\"_blank\">\n",
    "      prepare_data_loader()\n",
    "    </a>.\n",
    "  </li>\n",
    "  <li>Config that will be passed here, is defined below. It will be passed to the Ray Train's <a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchTrainer.html#ray-train-torch-torchtrainer\" target=\"_blank\">TorchTrainer</a>.</li>\n",
    "  <li>\n",
    "    <a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.v2.api.context.TrainContext.html#ray-train-v2-api-context-traincontext\" target=\"_blank\">\n",
    "      TrainContext\n",
    "    </a> lets users get useful information about the training i.e. node rank, world size, world rank, experiment name.\n",
    "  </li>\n",
    "\n",
    "  <li><code>load_model_ray_train</code> and <code>build_data_loader_ray_train</code> are implemented below.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop_config = {\n",
    "    \"num_epochs\": 2, \n",
    "    \"global_batch_size\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Configure scale and GPUs\n",
    "Outside of our training function, we create a `ScalingConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_config = ScalingConfig(num_workers=2, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.ScalingConfig.html#ray-train-scalingconfig\" target=\"_blank\">ScalingConfig</a> configures:\n",
    "\n",
    "<ul>\n",
    "  <li><code>num_workers</code>: The number of distributed training worker processes.</li>\n",
    "  <li><code>use_gpu</code>: Whether each worker should use a GPU (or CPU).</li>\n",
    "</ul>\n",
    "\n",
    "See docs on configuring <a href=\"https://docs.ray.io/en/latest/train/user-guides/using-gpus.html\" target=\"_blank\">scale and GPUs</a> for more details.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Note on Ray Train key concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray Train is built around [four key concepts](https://docs.ray.io/en/latest/train/overview.html):\n",
    "1. **Training function**: (implemented above `train_loop_ray_train`): A Python function that contains your model training logic.\n",
    "1. **Worker**: A process that runs the training function.\n",
    "1. **Scaling config**: specifices number of workers and compute resources (CPUs or GPUs, TPUs).\n",
    "1. **Trainer**: A Python class (Ray Actor) that ties together the training function, workers, and scaling configuration to execute a distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src=\"https://docs.ray.io/en/latest/_images/overview.png\" width=\"60%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|High-level architecture of how Ray Train|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Migrating the model to Ray Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`prepare_model()`](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_model.html#ray-train-torch-prepare-model) utility function to:\n",
    "\n",
    "* automatically move your model to the correct device,\n",
    "* wrap the model in PyTorch's DDP or FSDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_ray_train() -> torch.nn.Module:\n",
    "    model = build_resnet18()\n",
    "    model = ray.train.torch.prepare_model(model) # Instead of model = model.to(\"cuda\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "  <a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_model.html#ray-train-torch-prepare-model\" target=\"_blank\">\n",
    "    prepare_model()\n",
    "  </a> allows users to specify additional parameters:\n",
    "  <ul>\n",
    "    <li><code>parallel_strategy</code>: \"ddp\", \"fsdp\" â€“ wrap models in <code>DistributedDataParallel</code> or <code>FullyShardedDataParallel</code></li>\n",
    "    <li><code>parallel_strategy_kwargs</code>: pass additional arguments to \"ddp\" or \"fsdp\"</li>\n",
    "  </ul>\n",
    "  <p>\n",
    "    With <a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_model.html#ray-train-torch-prepare-model\" target=\"_blank\">\n",
    "      prepare_model()\n",
    "    </a> you can use the same code regardless of number of workers or the device type being used (CPU, GPU).\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Migrating the dataset to Ray Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`prepare_data_loader()`](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_data_loader.html#ray-train-torch-prepare-data-loader) utility function, to automatically:\n",
    "\n",
    "* move the batches to the right device,\n",
    "* copy data from host (CPU) memory to device (GPU) memory,\n",
    "* pass PyTorch's [`DistributedSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.distributed.DistributedSampler) to the DataLoader, if using more than 1 worker. Each worker will load a subset of the original dataset that is exclusive to it.\n",
    "\n",
    "[`prepare_data_loader()`](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_data_loader.html#ray-train-torch-prepare-data-loader) allows users to use the same code regardless of number of workers or the device type being used (CPU, GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_loader_ray_train(batch_size: int) -> torch.utils.data.DataLoader:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    train_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    # Automatically pass a DistributedSampler instance as a DataLoader sampler\n",
    "    train_loader = ray.train.torch.prepare_data_loader(train_loader)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>Ray Data integration</b>\n",
    "\n",
    "This step isn't necessary if you are integrating your Ray Train workload with Ray Data. It's especially useful if preprocessing is CPU-heavly and user wants to run preprocessing and training of separate instances.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Reporting checkpoints and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To monitor progress, we can continue to print/log metrics as before. This time we chose to log from all workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_ray_train(loss: torch.Tensor, epoch: int) -> None:\n",
    "    metrics = {\"loss\": loss.item(), \"epoch\": epoch}\n",
    "    world_rank = ray.train.get_context().get_world_rank() # report from all workers\n",
    "    print(f\"{metrics=} {world_rank=}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "If you want to log only from the rank 0 worker, use this code:\n",
    "\n",
    "```python\n",
    "def print_metrics_ray_train(loss: torch.Tensor, epoch: int) -> None:\n",
    "    metrics = {\"loss\": loss.item(), \"epoch\": epoch}\n",
    "    if ray.train.get_context().get_world_rank() == 0:  # report only from the rank 0 worker\n",
    "        print(f\"{metrics=} {world_rank=}\")\n",
    "    return metrics\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will report intermediate metrics and checkpoints using the [`ray.train.report`](https://docs.ray.io/en/latest/train/api/doc/ray.train.report.html#ray.train.report) utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_ray_train(\n",
    "    model: torch.nn.Module, metrics: dict[str, float]\n",
    ") -> None:\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        torch.save(\n",
    "            model.module.state_dict(),  # note the `.module` to unwrap the DistributedDataParallel\n",
    "            os.path.join(temp_checkpoint_dir, \"model.pt\"),\n",
    "        )\n",
    "\n",
    "        ray.train.report(\n",
    "            metrics,\n",
    "            checkpoint=ray.train.Checkpoint.from_directory(temp_checkpoint_dir),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "  <p><strong>Quick notes:</strong></p>\n",
    "  <ul>\n",
    "    <li>\n",
    "      Use \n",
    "      <a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.report.html#ray.train.report\" target=\"_blank\">\n",
    "        ray.train.report\n",
    "      </a> to save the metrics and checkpoint.\n",
    "    </li>\n",
    "    <li>Only metrics from the rank 0 worker are reported.</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.1. Note on the checkpoint lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the lifecycle of a checkpoint from being created using a local path to being uploaded to persistent storage.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/checkpoint_lifecycle.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "  <p><strong>Notes:</strong></p>\n",
    "  <ul>\n",
    "    <li>\n",
    "      Given it is the same model across all workers, we can instead only build the checkpoint on the worker of rank 0.\n",
    "      Note that we will still need to call \n",
    "      <a href=\"https://docs.ray.io/en/latest/train/api/doc/ray.train.report.html#ray.train.report\" target=\"_blank\">\n",
    "        ray.train.report\n",
    "      </a> on all workers to ensure that the training loop is synchronized.\n",
    "    </li>\n",
    "    <li>Ray Train expects all workers to be able to write files to the same persistent storage location.</li>\n",
    "    <li>Cloud storage is the recommended persistent storage location.</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_ray_train(\n",
    "    model: torch.nn.Module, metrics: dict[str, float]\n",
    ") -> None:\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        checkpoint = None\n",
    "\n",
    "        # checkpoint only from rank 0 worker\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "            torch.save(\n",
    "                model.module.state_dict(), os.path.join(temp_checkpoint_dir, \"model.pt\")\n",
    "            )\n",
    "            checkpoint = ray.train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "        ray.train.report(\n",
    "            metrics,\n",
    "            checkpoint=checkpoint,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our guide on [saving and loading checkpoints](https://docs.ray.io/en/latest/train/user-guides/checkpoints.html) for more details and best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Configure remote storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `RunConfig` object to specify the path where results (including checkpoints and artifacts) will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = \"/mnt/cluster_storage/training/\"\n",
    "run_config = RunConfig(storage_path=storage_path, name=\"distributed-mnist-resnet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. Launching the distributed training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed data-parallel training, but now using Ray Train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/multi_gpu_pytorch_annotated_v5.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now launch a distributed training job with a [`TorchTrainer`](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchTrainer.html#ray.train.torch.TorchTrainer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config=train_loop_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `trainer.fit()` will start the run and block until it completes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be able to observe relevant logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 23:24:34,611\tINFO worker.py:1832 -- Connecting to existing Ray cluster at address: 10.0.60.67:6379...\n",
      "2026-01-26 23:24:34,622\tINFO worker.py:2003 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-g6iqlxs5pyemfy8rf3nywleh83.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2026-01-26 23:24:34,782\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_ec331c179880b128fd10f91882efe32aca08b69b.zip' (63.53MiB) to Ray cluster...\n",
      "2026-01-26 23:24:35,059\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_ec331c179880b128fd10f91882efe32aca08b69b.zip'.\n",
      "/home/ray/anaconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [State Transition] INITIALIZING -> SCHEDULING.\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'GPU': 1}] * 2\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [FailurePolicy] Decision: FailureDecision.RETRY, Error source: controller, Error count / maximum errors allowed: 1/inf, Error: Training failed due to controller error:\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m The worker group startup timed out after 30.0 seconds waiting for 2 workers. Potential causes include: (1) temporary insufficient cluster resources while waiting for autoscaling (ignore this warning in this case), (2) infeasible resource request where the provided `ScalingConfig` cannot be satisfied), and (3) transient network issues. Set the RAY_TRAIN_WORKER_GROUP_START_TIMEOUT_S environment variable to increase the timeout.\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [State Transition] SCHEDULING -> RESCHEDULING.\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [State Transition] RESCHEDULING -> SCHEDULING.\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'GPU': 1}] * 2\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [FailurePolicy] Decision: FailureDecision.RETRY, Error source: controller, Error count / maximum errors allowed: 2/inf, Error: Training failed due to controller error:\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m The worker group startup timed out after 30.0 seconds waiting for 2 workers. Potential causes include: (1) temporary insufficient cluster resources while waiting for autoscaling (ignore this warning in this case), (2) infeasible resource request where the provided `ScalingConfig` cannot be satisfied), and (3) transient network issues. Set the RAY_TRAIN_WORKER_GROUP_START_TIMEOUT_S environment variable to increase the timeout.\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [State Transition] SCHEDULING -> RESCHEDULING.\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [State Transition] RESCHEDULING -> SCHEDULING.\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'GPU': 1}] * 2\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m Started training worker group of size 2: \n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m - (ip=10.0.14.21, pid=33774) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m - (ip=10.0.14.21, pid=33777) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [State Transition] SCHEDULING -> RUNNING.\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m Moving model to device: cuda:0\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m world_size=2\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m batch_size=64\n",
      "\u001b[36m(RayTrainWorker pid=33777, ip=10.0.14.21)\u001b[0m world_size=2\n",
      "\u001b[36m(RayTrainWorker pid=33777, ip=10.0.14.21)\u001b[0m batch_size=64\n",
      "  0%|          | 0.00/9.91M [00:00<?, ?B/s]21)\u001b[0m \n",
      "  1%|          | 98.3k/9.91M [00:00<00:10, 894kB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 16.2MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 16.6MB/s]\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m metrics={'loss': 0.30348682403564453, 'epoch': 0} world_rank=0\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 24.1MB/s]\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 3.76MB/s]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=33777, ip=10.0.14.21)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=None, metrics={'loss': 0.2710075378417969, 'epoch': 0}, validation_spec=None)\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/distributed-mnist-resnet18/checkpoint_2026-01-26_23-26-31.570128)\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/distributed-mnist-resnet18/checkpoint_2026-01-26_23-26-31.570128), metrics={'loss': 0.30348682403564453, 'epoch': 0}, validation_spec=None)\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m metrics={'loss': 0.14724265038967133, 'epoch': 1} world_rank=0\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=33777, ip=10.0.14.21)\u001b[0m Reporting training result 2: TrainingReport(checkpoint=None, metrics={'loss': 0.15123265981674194, 'epoch': 1}, validation_spec=None)\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/distributed-mnist-resnet18/checkpoint_2026-01-26_23-26-45.051078)\n",
      "\u001b[36m(RayTrainWorker pid=33774, ip=10.0.14.21)\u001b[0m Reporting training result 2: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/distributed-mnist-resnet18/checkpoint_2026-01-26_23-26-45.051078), metrics={'loss': 0.14724265038967133, 'epoch': 1}, validation_spec=None)\n",
      "\u001b[36m(TrainController pid=129185)\u001b[0m [State Transition] RUNNING -> FINISHED.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +9m38s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. Access the training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training completes, a `Result` object is returned which contains information about the training run, including the metrics and checkpoints reported during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(metrics={'loss': 0.14724265038967133, 'epoch': 1}, checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/distributed-mnist-resnet18/checkpoint_2026-01-26_23-26-45.051078), error=None, path='/mnt/cluster_storage/training/distributed-mnist-resnet18', metrics_dataframe=       loss  epoch\n",
       "0  0.303487      0\n",
       "1  0.147243      1, best_checkpoints=[(Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/distributed-mnist-resnet18/checkpoint_2026-01-26_23-26-31.570128), {'loss': 0.30348682403564453, 'epoch': 0}), (Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/distributed-mnist-resnet18/checkpoint_2026-01-26_23-26-45.051078), {'loss': 0.14724265038967133, 'epoch': 1})], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x7ff7443b8c30>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the metrics produced by the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  epoch\n",
       "0  0.303487      0\n",
       "1  0.147243      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9. Use checkpointed model to generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the latest checkpoint and load it to inspect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = result.checkpoint\n",
    "with ckpt.as_directory() as ckpt_dir:\n",
    "    model_path = os.path.join(ckpt_dir, \"model.pt\")\n",
    "    loaded_model_ray_train = build_resnet18()\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'), weights_only=True)\n",
    "    loaded_model_ray_train.load_state_dict(state_dict)\n",
    "    loaded_model_ray_train.to(\"cuda\")\n",
    "    loaded_model_ray_train.eval()\n",
    "\n",
    "loaded_model_ray_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "  <p>\n",
    "    To learn more about the training results, see this \n",
    "    <a href=\"https://docs.ray.io/en/latest/train/user-guides/results.html\" target=\"_blank\">\n",
    "      docs\n",
    "    </a> on inspecting the training results.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions on randomly selected 9 images rom the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = np.random.randint(0, len(dataset.data))\n",
    "    img, label = dataset[sample_idx]\n",
    "    normalized_img = Normalize((0.5,), (0.5,))(ToTensor()(img))\n",
    "    normalized_img = normalized_img.to(\"cuda\")\n",
    "\n",
    "    # use loaded model to generate preds\n",
    "    with torch.no_grad():        \n",
    "        prediction = loaded_model_ray_train(normalized_img.unsqueeze(0)).argmax().cpu()\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"label: {label}; pred: {int(prediction)}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10. Activity: Run the distributed training with more workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "1. Update the scaling configuration to make use of 4 GPU workers\n",
    "2. Run the trainer using the same hypeparameters\n",
    "\n",
    "Use the following code snippets to guide you:\n",
    "\n",
    "```python\n",
    "# Hint: Update the scaling configuration\n",
    "scaling_config = ...\n",
    "\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n",
    "result = trainer.fit()\n",
    "result.metrics_dataframe\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click here to see the solution </summary>\n",
    "\n",
    "```python\n",
    "scaling_config = ScalingConfig(num_workers=4, use_gpu=True)\n",
    "\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n",
    "result = trainer.fit()\n",
    "result.metrics_dataframe\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrating Ray Train with Ray Data\n",
    "\n",
    "### 3.1 When to integrate Ray Train with Ray Data\n",
    "Use both Ray Train and Ray Data when you face one of the following challenges:\n",
    "| Challenge | Detail | Solution |\n",
    "| --- | --- | --- |\n",
    "| Need to perform online or just-in-time data processing | The training pipeline requires processing data on the fly, such as data augmentation, normalization, or other transformations that may differ for each training epoch. | Ray Train's integration with Ray Data makes it easy to implement just-in-time data processing. |\n",
    "| Need to improve hardware utilization | Training and data processing need to be scaled independently to keep GPUs fully utilized, especially when preprocessing is CPU-intensive. | Ray Data can distribute data processing across multiple CPU nodes, while Ray Train runs the training loop on GPUs. |\n",
    "| Need a consistent interface for loading data | The training process may need to load data from various sources, such as Parquet, CSV, or lakehouses. | Ray Data provides a consistent interface for loading, shuffling, sharding, and batching data for training loops. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a diagram showing the Ray Data and Ray Train integration\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-train-deep-dive/ray_train_v2_architecture.png\" width=\"1200\" loading=\"lazy\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Integrating Ray Train with Ray Data\n",
    "\n",
    "Here is how our training loop will look like using **Ray Data** instead of the **PyTorch DataLoader**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_ray_train_ray_data(config: dict):\n",
    "    # Same initialization as before\n",
    "    criterion = CrossEntropyLoss()\n",
    "    model = load_model_ray_train()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # This time we use Ray Train's integration with Ray Data to load the data\n",
    "    global_batch_size = config[\"global_batch_size\"]\n",
    "    batch_size = global_batch_size // ray.train.get_context().get_world_size()\n",
    "    data_loader = build_data_loader_ray_train_ray_data(batch_size=batch_size) \n",
    "    \n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        # No longer need to ensure data is on the correct device\n",
    "        # data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        # Note our batches are now dictionaries instead of tuples\n",
    "        for batch in data_loader: \n",
    "            outputs = model(batch[\"image\"])\n",
    "            loss = criterion(outputs, batch[\"label\"])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        metrics = print_metrics_ray_train(loss, epoch)\n",
    "        save_checkpoint_and_metrics_ray_train(model, metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the updated `build_data_loader_ray_train_ray_data` function that uses Ray Data to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_loader_ray_train_ray_data(\n",
    "    batch_size: int, prefetch_batches: int = 2\n",
    "):\n",
    "    dataset_iterator = ray.train.get_dataset_shard(\"train\")\n",
    "    data_loader = dataset_iterator.iter_torch_batches(\n",
    "        batch_size=batch_size, prefetch_batches=prefetch_batches\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note** Use the `iter_torch_batches` function to build a torch compatible data loader.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Preparing the data\n",
    "Let's store the training data in a format that Ray Data can easily read. \n",
    "\n",
    "Let's use the Parquet format, which is a columnar storage format that is efficient for reading and writing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"image\": dataset.data.tolist(), \"label\": dataset.targets})\n",
    "df.to_parquet(\"/mnt/cluster_storage/cifar10.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, construct a Ray Data Dataset from the Parquet source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ray.data.read_parquet(\"/mnt/cluster_storage/cifar10.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same preprocessing steps that pytorch data loader does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(row: dict):\n",
    "    # Define the torchvision transform.\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    image_arr = np.array(row[\"image\"], dtype=np.uint8)\n",
    "    row[\"image\"] = transform(Image.fromarray(image_arr))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note** Unlike the PyTorch DataLoader, the preprocessing can now occur on any node in the cluster.\n",
    "\n",
    "The data will be passed to training workers via the ray object store (a distributed in-memory object store).\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(transform_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the constructed `train_ds` to the `TorchTrainer` via the `datasets` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"train\": train_ds}\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train_ray_data,\n",
    "    train_loop_config={\"num_epochs\": 1, \"global_batch_size\": 512},\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=RunConfig(storage_path=storage_path, name=\"dist-cifar-res18-ray-data\"),\n",
    "    datasets=datasets,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `trainer.fit()` will now use Ray Data to load and shard the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=131788)\u001b[0m [State Transition] INITIALIZING -> SCHEDULING.\n",
      "\u001b[36m(TrainController pid=131788)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'GPU': 1}] * 2\n",
      "\u001b[36m(RayTrainWorker pid=33775, ip=10.0.14.21)\u001b[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[36m(TrainController pid=131788)\u001b[0m Started training worker group of size 2: \n",
      "\u001b[36m(TrainController pid=131788)\u001b[0m - (ip=10.0.14.21, pid=33775) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TrainController pid=131788)\u001b[0m - (ip=10.0.14.21, pid=34517) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TrainController pid=131788)\u001b[0m [State Transition] SCHEDULING -> RUNNING.\n",
      "\u001b[36m(RayTrainWorker pid=33775, ip=10.0.14.21)\u001b[0m Moving model to device: cuda:0\n",
      "\u001b[36m(RayTrainWorker pid=33775, ip=10.0.14.21)\u001b[0m Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[36m(SplitCoordinator pid=132016)\u001b[0m A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True`.\n",
      "\u001b[36m(SplitCoordinator pid=132016)\u001b[0m Registered dataset logger for dataset train_14_0\n",
      "\u001b[36m(SplitCoordinator pid=132016)\u001b[0m Starting execution of Dataset train_14_0. Full logs are in /tmp/ray/session_2026-01-26_18-07-56_208174_3401/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=132016)\u001b[0m Execution plan of Dataset train_14_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[Map(transform_images)] -> OutputSplitter[split(2, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=132016)\u001b[0m âš ï¸  Ray's object store is configured to use only 28.6% of available memory (114.4GiB out of 400.0GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315ece8db9cd4d969d1857b62006fd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=132016) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195e32df39b24d1887a77c12af0ba98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=132016) - ListFiles 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c116e997f649c484b699ba9264b849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=132016) - ReadFiles 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab1c92397604a17959287173eb4a980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=132016) - Map(transform_images) 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954d4061b53741d78bbb4eda2caf51fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=132016) - split(2, equal=True) 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=132016)\u001b[0m âœ”ï¸  Dataset train_14_0 execution finished in 19.22 seconds\n",
      "\u001b[36m(RayTrainWorker pid=33775, ip=10.0.14.21)\u001b[0m Exiting prefetcher's background thread\n",
      "\u001b[36m(RayTrainWorker pid=33775, ip=10.0.14.21)\u001b[0m metrics={'loss': 0.11886263638734818, 'epoch': 0} world_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=34517, ip=10.0.14.21)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=None, metrics={'loss': 0.11459239572286606, 'epoch': 0}, validation_spec=None)\n",
      "\u001b[36m(RayTrainWorker pid=33775, ip=10.0.14.21)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/dist-cifar-res18-ray-data/checkpoint_2026-01-26_23-31-41.995428)\n",
      "\u001b[36m(RayTrainWorker pid=33775, ip=10.0.14.21)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/dist-cifar-res18-ray-data/checkpoint_2026-01-26_23-31-41.995428), metrics={'loss': 0.11886263638734818, 'epoch': 0}, validation_spec=None)\n",
      "\u001b[36m(TrainController pid=131788)\u001b[0m [State Transition] RUNNING -> FINISHED.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(metrics={'loss': 0.11886263638734818, 'epoch': 0}, checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/dist-cifar-res18-ray-data/checkpoint_2026-01-26_23-31-41.995428), error=None, path='/mnt/cluster_storage/training/dist-cifar-res18-ray-data', metrics_dataframe=       loss  epoch\n",
       "0  0.118863      0, best_checkpoints=[(Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/dist-cifar-res18-ray-data/checkpoint_2026-01-26_23-31-41.995428), {'loss': 0.11886263638734818, 'epoch': 0})], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x7ff55a84aab0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fault Tolerance in Ray Train\n",
    "\n",
    "Ray Train provides two main mechanisms to handle failures:\n",
    "\n",
    "- Automatic retries\n",
    "- Manual restoration\n",
    "\n",
    "Here is a diagram showing these two primary mechanisms:\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-summit/stable-diffusion/diagrams/fault_tolerant_cropped_v2.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modifying the Training Loop to Enable Checkpoint Loading\n",
    "\n",
    "We need to make use of `get_checkpoint()` in the training loop to enable checkpoint loading for fault tolerance.\n",
    "\n",
    "Here is how the modified training loop looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_ray_train_with_checkpoint_loading(config: dict):\n",
    "    # Same initialization of loss, model, optimizer as before\n",
    "    criterion = CrossEntropyLoss()\n",
    "    model = load_model_ray_train()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Same initialization of the data loader as before\n",
    "    global_batch_size = config[\"global_batch_size\"]\n",
    "    batch_size = global_batch_size // ray.train.get_context().get_world_size()\n",
    "    data_loader = build_data_loader_ray_train_ray_data(batch_size=batch_size)\n",
    "\n",
    "    # Assume we start from epoch 0 unless we find a checkpoint\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Load the latest checkpoint if it exists\n",
    "    checkpoint = ray.train.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        # Continue training from a previous checkpoint\n",
    "        with checkpoint.as_directory() as ckpt_dir:\n",
    "            model_state_dict = torch.load(\n",
    "                os.path.join(ckpt_dir, \"model.pt\"),\n",
    "            )\n",
    "            # Load the model and optimizer state\n",
    "            model.module.load_state_dict(model_state_dict)\n",
    "            optimizer.load_state_dict(\n",
    "                torch.load(os.path.join(ckpt_dir, \"optimizer.pt\"))\n",
    "            )\n",
    "\n",
    "            # Load the last epoch from the extra state\n",
    "            start_epoch = (\n",
    "                torch.load(os.path.join(ckpt_dir, \"extra_state.pt\"))[\"epoch\"] + 1\n",
    "            )\n",
    "\n",
    "    # Same loop as before except it starts at a parameterized start_epoch\n",
    "    for epoch in range(start_epoch, config[\"num_epochs\"]):\n",
    "        for batch in data_loader:\n",
    "            outputs = model(batch[\"image\"])\n",
    "            loss = criterion(outputs, batch[\"label\"])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        metrics = print_metrics_ray_train(loss,  epoch)\n",
    "        # We now save the optimizer and epoch state in addition to the model\n",
    "        save_checkpoint_and_metrics_ray_train_with_extra_state(\n",
    "            model, metrics, optimizer, epoch\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to update the checkpoint saving function to save the optimizer and epoch state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_ray_train_with_extra_state(\n",
    "    model: torch.nn.Module,\n",
    "    metrics: dict[str, float],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        checkpoint = None\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "                # === Make sure to save all state needed for resuming training ===\n",
    "                torch.save(\n",
    "                    model.module.state_dict(),  # NOTE: Unwrap the model.\n",
    "                    os.path.join(temp_checkpoint_dir, \"model.pt\"),\n",
    "                )\n",
    "                torch.save(\n",
    "                    optimizer.state_dict(),\n",
    "                    os.path.join(temp_checkpoint_dir, \"optimizer.pt\"),\n",
    "                )\n",
    "                torch.save(\n",
    "                    {\"epoch\": epoch},\n",
    "                    os.path.join(temp_checkpoint_dir, \"extra_state.pt\"),\n",
    "                )\n",
    "                # ================================================================\n",
    "                checkpoint = ray.train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "        \n",
    "        ray.train.report(  # use ray.train.report to save the metrics and checkpoint\n",
    "            metrics,  # train.report will only save worker rank 0's metrics\n",
    "            checkpoint=checkpoint,\n",
    "            )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Configuring Automatic Retries\n",
    "Now that we have enabled checkpoint loading, we can configure a failure config which sets the maximum number of retries for a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_config = ray.train.FailureConfig(max_failures=3)\n",
    "experiment_name = \"fault-tolerant-cifar-vit\"\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_ray_train_with_checkpoint_loading,\n",
    "    train_loop_config={\"num_epochs\": 1, \"global_batch_size\": 512},\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=ray.train.RunConfig(\n",
    "        name=\"fault-tolerant-cifar-vit\",\n",
    "        storage_path=storage_path,\n",
    "        failure_config=failure_config, # Pass the failure config\n",
    "    ),\n",
    "    datasets=datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to run the training job as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=136473)\u001b[0m [State Transition] INITIALIZING -> SCHEDULING.\n",
      "\u001b[36m(TrainController pid=136473)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'GPU': 1}] * 2\n",
      "\u001b[36m(RayTrainWorker pid=33607, ip=10.0.45.247)\u001b[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[36m(TrainController pid=136473)\u001b[0m Started training worker group of size 2: \n",
      "\u001b[36m(TrainController pid=136473)\u001b[0m - (ip=10.0.45.247, pid=33607) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TrainController pid=136473)\u001b[0m - (ip=10.0.45.247, pid=33608) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TrainController pid=136473)\u001b[0m [State Transition] SCHEDULING -> RUNNING.\n",
      "\u001b[36m(RayTrainWorker pid=33607, ip=10.0.45.247)\u001b[0m Moving model to device: cuda:0\n",
      "\u001b[36m(RayTrainWorker pid=33607, ip=10.0.45.247)\u001b[0m Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[36m(SplitCoordinator pid=136661)\u001b[0m A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True`.\n",
      "\u001b[36m(SplitCoordinator pid=136661)\u001b[0m Registered dataset logger for dataset train_16_0\n",
      "\u001b[36m(SplitCoordinator pid=136661)\u001b[0m Starting execution of Dataset train_16_0. Full logs are in /tmp/ray/session_2026-01-26_18-07-56_208174_3401/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=136661)\u001b[0m Execution plan of Dataset train_16_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[Map(transform_images)] -> OutputSplitter[split(2, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=136661)\u001b[0m âš ï¸  Ray's object store is configured to use only 28.6% of available memory (114.4GiB out of 400.0GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4218a9f284e43dbb9fd7381ed2b3d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=136661) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750ee027480842948aadced51cafd156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=136661) - ListFiles 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc34e648afb4448afb73736e7f8954d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=136661) - ReadFiles 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d0243399674834a02ff64f402f7ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=136661) - Map(transform_images) 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ec3d3538e643f48119846849369a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=136661) - split(2, equal=True) 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=136661)\u001b[0m âœ”ï¸  Dataset train_16_0 execution finished in 14.08 seconds\n",
      "\u001b[36m(RayTrainWorker pid=33608, ip=10.0.45.247)\u001b[0m Exiting prefetcher's background thread\n",
      "\u001b[36m(RayTrainWorker pid=33608, ip=10.0.45.247)\u001b[0m metrics={'loss': 0.32932791113853455, 'epoch': 0} world_rank=1\n",
      "\u001b[36m(RayTrainWorker pid=33608, ip=10.0.45.247)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=None, metrics={'loss': 0.32932791113853455, 'epoch': 0}, validation_spec=None)\n",
      "\u001b[36m(RayTrainWorker pid=33607, ip=10.0.45.247)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/fault-tolerant-cifar-vit/checkpoint_2026-01-26_23-44-01.396265)\n",
      "\u001b[36m(RayTrainWorker pid=33607, ip=10.0.45.247)\u001b[0m Reporting training result 1: TrainingReport(checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/fault-tolerant-cifar-vit/checkpoint_2026-01-26_23-44-01.396265), metrics={'loss': 0.027947090566158295, 'epoch': 0}, validation_spec=None)\n",
      "\u001b[36m(TrainController pid=136473)\u001b[0m [State Transition] RUNNING -> FINISHED.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(metrics={'loss': 0.027947090566158295, 'epoch': 0}, checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/fault-tolerant-cifar-vit/checkpoint_2026-01-26_23-44-01.396265), error=None, path='/mnt/cluster_storage/training/fault-tolerant-cifar-vit', metrics_dataframe=       loss  epoch\n",
       "0  0.027947      0, best_checkpoints=[(Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/fault-tolerant-cifar-vit/checkpoint_2026-01-26_23-44-01.396265), {'loss': 0.027947090566158295, 'epoch': 0})], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x7ff55a8a2cf0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Performing a Manual Restoration\n",
    "\n",
    "In case the retries are exhausted, we can perform a manual restoration by re-initializing the TorchTrainer with the same `run_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_ray_train_with_checkpoint_loading,\n",
    "    train_loop_config={\"num_epochs\": 1, \"global_batch_size\": 512},\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=ray.train.RunConfig(\n",
    "        name=\"fault-tolerant-cifar-vit\",\n",
    "        storage_path=storage_path,\n",
    "        failure_config=failure_config, # Pass the failure config\n",
    "    ),\n",
    "    datasets=datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the fit method will resume training from the last checkpoint.\n",
    "\n",
    "Given we already have completed all epochs, we expect the training to terminate immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=137084)\u001b[0m A run snapshot was found in storage folder at: '/mnt/cluster_storage/training/fault-tolerant-cifar-vit'\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m This snapshot contains a list of checkpoints reported via `ray.train.report` and will be loaded. This allows the latest checkpoint found in the snapshot to be accessible within your training function via `ray.train.get_checkpoint`.\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m If you meant to start a brand new training job without any information about previous checkpoints found in this directory, please configure a new, unique `RunConfig(name)` or delete the existing folder at '/mnt/cluster_storage/training/fault-tolerant-cifar-vit'.\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m [State Transition] INITIALIZING -> SCHEDULING.\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'GPU': 1}] * 2\n",
      "\u001b[36m(RayTrainWorker pid=34946, ip=10.0.45.247)\u001b[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m Started training worker group of size 2: \n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m - (ip=10.0.45.247, pid=34946) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m - (ip=10.0.45.247, pid=34947) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m [State Transition] SCHEDULING -> RUNNING.\n",
      "\u001b[36m(RayTrainWorker pid=34946, ip=10.0.45.247)\u001b[0m Moving model to device: cuda:0\n",
      "\u001b[36m(RayTrainWorker pid=34946, ip=10.0.45.247)\u001b[0m Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[36m(TrainController pid=137084)\u001b[0m [State Transition] RUNNING -> FINISHED.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(metrics={'loss': 0.027947090566158295, 'epoch': 0}, checkpoint=Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/fault-tolerant-cifar-vit/checkpoint_2026-01-26_23-44-01.396265), error=None, path='/mnt/cluster_storage/training/fault-tolerant-cifar-vit', metrics_dataframe=       loss  epoch\n",
       "0  0.027947      0, best_checkpoints=[(Checkpoint(filesystem=local, path=/mnt/cluster_storage/training/fault-tolerant-cifar-vit/checkpoint_2026-01-26_23-44-01.396265), {'loss': 0.027947090566158295, 'epoch': 0})], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x7ff55a8cd570>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = restored_trainer.fit()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ray Train in Production\n",
    "\n",
    "Here are some use-cases of using Ray Train in production:\n",
    "1. Canva uses Ray Train + Ray Data to cut down Stable Diffusion training costs by 3.7x. Read this [Anyscale blog post here](https://www.anyscale.com/blog/scalable-and-cost-efficient-stable-diffusion-pre-training-with-ray) and the [Canva  case study here](https://www.anyscale.com/resources/case-study/how-canva-built-a-modern-ai-platform-using-anyscale)\n",
    "2. Anyscale uses Ray Train + Deepspeed to finetune language models. Read more [here](https://github.com/ray-project/ray/tree/master/doc/source/templates/04_finetuning_llms_with_deepspeed).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "orphan": true,
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
